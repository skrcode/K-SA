{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/16521/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "import errno\n",
    "import csv\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk.data\n",
    "import nltk\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from subprocess import check_call\n",
    "from shutil import copyfile\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = \"../data/train.csv\"\n",
    "test = \"../data/test.csv\"\n",
    "wv = \"../../../../glove.6B/glove.6B.50d.txt\"\n",
    "X_train = pd.read_csv( train, header=0,delimiter=\",\" )\n",
    "X_test = pd.read_csv( test, header=0,delimiter=\",\" )\n",
    "\n",
    "word_vecs = {}\n",
    "with open(wv) as f:\n",
    "    for line in f:\n",
    "       vals = line.split()\n",
    "       word_vecs[vals[0]] = np.array(vals[1::],dtype=float)\n",
    "authors = ['EAP','MWS','HPL']\n",
    "\n",
    "Y_train = LabelEncoder().fit_transform(X_train['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def getWordVectors(X_train,X_test,word_vecs):\n",
    "    X_train['word_vectors'] = [ [ word_vecs[word] for word in sentence if word in word_vecs] for sentence in X_train['text']]\n",
    "    X_test['word_vectors'] = [ [ word_vecs[word] for word in sentence if word in word_vecs] for sentence in X_test['text']] \n",
    "    return X_train,X_test\n",
    "\n",
    "def getSentenceVectors(X_train,X_test):\n",
    "    X_train['sentence_vectors'] =[np.mean(sentence,axis = 0) for sentence in X_train['word_vectors']]\n",
    "    X_test['sentence_vectors'] =[np.mean(sentence,axis = 0) for sentence in X_test['word_vectors']] \n",
    "    return X_train,X_test\n",
    "\n",
    "def clean(X_train,X_test):\n",
    "    X_train['words'] = [re.sub(\"[^a-zA-Z]\",\" \", data).lower().split() for data in X_train['text']]\n",
    "    X_test['words'] = [re.sub(\"[^a-zA-Z]\",\" \", data).lower().split() for data in X_test['text']]\n",
    "    return X_train,X_test\n",
    "X_train,X_test = clean(X_train,X_test)\n",
    "X_train,X_test = getWordVectors(X_train,X_test,word_vecs)\n",
    "X_train,X_test = getSentenceVectors(X_train,X_test)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Punctuation\n",
    "punctuations = [{\"id\":1,\"p\":\"[;:]\"},{\"id\":2,\"p\":\"[,.]\"},{\"id\":3,\"p\":\"[?]\"},{\"id\":4,\"p\":\"[\\']\"},{\"id\":5,\"p\":\"[\\\"]\"},{\"id\":6,\"p\":\"[;:,.?\\'\\\"]\"}]\n",
    "for p in punctuations:\n",
    "    punctuation = p[\"p\"]\n",
    "    _train =  [ sentence.split() for sentence in X_train['text'] ]\n",
    "    X_train['punc_'+str(p[\"id\"])] = [len([word for word in sentence if bool(re.search(punctuation, word))])*100.0/len(sentence) for sentence in _train]    \n",
    "\n",
    "    _test =  [ sentence.split() for sentence in X_test['text'] ]\n",
    "    X_test['punc_'+str(p[\"id\"])] = [len([word for word in sentence if bool(re.search(punctuation, word))])*100.0/len(sentence) for sentence in _test]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Stop Words\n",
    "_dist_train = [x for x in X_train['words']]\n",
    "X_train['stop_word'] = [len([word for word in sentence if word in stopwords.words('english')])*100.0/len(sentence) for sentence in _dist_train]\n",
    "\n",
    "_dist_test = [x for x in X_test['words']]\n",
    "X_test['stop_word'] = [len([word for word in sentence if word in stopwords.words('english')])*100.0/len(sentence) for sentence in _dist_test]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean cv score : ', 0.84221619836128525)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# tfidf - words - nb+svd\n",
    "def tfidfWords(X_train,X_test):\n",
    "    tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "    full_tfidf = tfidf_vec.fit_transform(X_train['text'].values.tolist() + X_test['text'].values.tolist())\n",
    "    train_tfidf = tfidf_vec.transform(X_train['text'].values.tolist())\n",
    "    test_tfidf = tfidf_vec.transform(X_test['text'].values.tolist())\n",
    "    return train_tfidf,test_tfidf,full_tfidf\n",
    "    \n",
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def runSVD(full_tfidf,train_tfidf,test_tfidf):   \n",
    "    n_comp = 20\n",
    "    svd_obj = TruncatedSVD(n_components=n_comp)\n",
    "    svd_obj.fit(full_tfidf)\n",
    "    train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "    test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "\n",
    "    train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "    test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "    return train_svd,test_svd\n",
    "\n",
    "def do_tfidf_MNB(X_train,X_test,Y_train):\n",
    "    train_tfidf,test_tfidf,full_tfidf = tfidfWords(X_train,X_test)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([X_train.shape[0], 3])\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    for dev_index, val_index in kf.split(X_train):\n",
    "        dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "        dev_y, val_y = Y_train[dev_index], Y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "    pred_full_test = pred_full_test / 5.\n",
    "    return pred_train,pred_full_test\n",
    "\n",
    "def do_tfidf_SVD(X_train,X_test,Y_train):\n",
    "    train_tfidf,test_tfidf,full_tfidf = tfidfWords(X_train,X_test)\n",
    "    train_svd,test_svd = runSVD(full_tfidf,train_tfidf,test_tfidf)\n",
    "    return train_svd,test_svd\n",
    "\n",
    "pred_train,pred_test = do_tfidf_MNB(X_train,X_test,Y_train)\n",
    "X_train[\"tfidf_words_nb_eap\"] = pred_train[:,0]\n",
    "X_train[\"tfidf_words_nb_hpl\"] = pred_train[:,1]\n",
    "X_train[\"tfidf_words_nb_mws\"] = pred_train[:,2]\n",
    "X_test[\"tfidf_words_nb_eap\"] = pred_test[:,0]\n",
    "X_test[\"tfidf_words_nb_hpl\"] = pred_test[:,1]\n",
    "X_test[\"tfidf_words_nb_mws\"] = pred_test[:,2]\n",
    "\n",
    "# pred_train,pred_test = do_tfidf_SVD(X_train,X_test,Y_train)\n",
    "# print pred_train\n",
    "# # X_train[\"tfidf_words_nb_eap\"] = pred_train[:,0]\n",
    "# # X_train[\"tfidf_words_nb_hpl\"] = pred_train[:,1]\n",
    "# # X_train[\"tfidf_words_nb_mws\"] = pred_train[:,2]\n",
    "# # X_test[\"tfidf_words_nb_eap\"] = pred_test[:,0]\n",
    "# # X_test[\"tfidf_words_nb_hpl\"] = pred_test[:,1]\n",
    "# # X_test[\"tfidf_words_nb_mws\"] = pred_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean cv score : ', 0.7904152589474216)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# tfidf - chars - nb+svd\n",
    "def tfidfWords(X_train,X_test):\n",
    "    tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,5),analyzer='char')\n",
    "    full_tfidf = tfidf_vec.fit_transform(X_train['text'].values.tolist() + X_test['text'].values.tolist())\n",
    "    train_tfidf = tfidf_vec.transform(X_train['text'].values.tolist())\n",
    "    test_tfidf = tfidf_vec.transform(X_test['text'].values.tolist())\n",
    "    return train_tfidf,test_tfidf\n",
    "    \n",
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def do(X_train,X_test,Y_train):\n",
    "    train_tfidf,test_tfidf = tfidfWords(X_train,X_test)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([X_train.shape[0], 3])\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    for dev_index, val_index in kf.split(X_train):\n",
    "        dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "        dev_y, val_y = Y_train[dev_index], Y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "    pred_full_test = pred_full_test / 5.\n",
    "    return pred_train,pred_full_test\n",
    "pred_train,pred_test = do(X_train,X_test,Y_train)\n",
    "X_train[\"tfidf_chars_nb_eap\"] = pred_train[:,0]\n",
    "X_train[\"tfidf_chars_nb_hpl\"] = pred_train[:,1]\n",
    "X_train[\"tfidf_chars_nb_mws\"] = pred_train[:,2]\n",
    "X_test[\"tfidf_chars_nb_eap\"] = pred_test[:,0]\n",
    "X_test[\"tfidf_chars_nb_hpl\"] = pred_test[:,1]\n",
    "X_test[\"tfidf_chars_nb_mws\"] = pred_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean cv score : ', 0.45091841616567468)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# count - words - nb\n",
    "def countWords(X_train,X_test):\n",
    "    count_vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "    count_vec.fit(X_train['text'].values.tolist() + X_test['text'].values.tolist())\n",
    "    train_count = count_vec.transform(X_train['text'].values.tolist())\n",
    "    test_count = count_vec.transform(X_test['text'].values.tolist())\n",
    "    return train_count,test_count\n",
    "    \n",
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def do_count_MNB(X_train,X_test,Y_train):\n",
    "    train_count,test_count=countWords(X_train,X_test)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([X_train.shape[0], 3])\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    for dev_index, val_index in kf.split(X_train):\n",
    "        dev_X, val_X = train_count[dev_index], train_count[val_index]\n",
    "        dev_y, val_y = Y_train[dev_index], Y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_count)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "    pred_full_test = pred_full_test / 5.\n",
    "    return pred_train,pred_full_test\n",
    "\n",
    "pred_train,pred_test = do_count_MNB(X_train,X_test,Y_train)\n",
    "X_train[\"count_words_nb_eap\"] = pred_train[:,0]\n",
    "X_train[\"count_words_nb_hpl\"] = pred_train[:,1]\n",
    "X_train[\"count_words_nb_mws\"] = pred_train[:,2]\n",
    "X_test[\"count_words_nb_eap\"] = pred_test[:,0]\n",
    "X_test[\"count_words_nb_hpl\"] = pred_test[:,1]\n",
    "X_test[\"count_words_nb_mws\"] = pred_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean cv score : ', 3.750763922681903)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# count - chars - nb\n",
    "def countChars(X_train,X_test):\n",
    "    count_vec = CountVectorizer(ngram_range=(1,7),analyzer='char')\n",
    "    count_vec.fit(X_train['text'].values.tolist() + X_test['text'].values.tolist())\n",
    "    train_count = count_vec.transform(X_train['text'].values.tolist())\n",
    "    test_count = count_vec.transform(X_test['text'].values.tolist())\n",
    "    return train_count,test_count\n",
    "    \n",
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def do_count_chars_MNB(X_train,X_test,Y_train):\n",
    "    train_count,test_count=countChars(X_train,X_test)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([X_train.shape[0], 3])\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    for dev_index, val_index in kf.split(X_train):\n",
    "        dev_X, val_X = train_count[dev_index], train_count[val_index]\n",
    "        dev_y, val_y = Y_train[dev_index], Y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_count)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "    pred_full_test = pred_full_test / 5.\n",
    "    return pred_train,pred_full_test\n",
    "\n",
    "pred_train,pred_test = do_count_chars_MNB(X_train,X_test,Y_train)\n",
    "X_train[\"count_chars_nb_eap\"] = pred_train[:,0]\n",
    "X_train[\"count_chars_nb_hpl\"] = pred_train[:,1]\n",
    "X_train[\"count_chars_nb_mws\"] = pred_train[:,2]\n",
    "X_test[\"count_chars_nb_eap\"] = pred_test[:,0]\n",
    "X_test[\"count_chars_nb_hpl\"] = pred_test[:,1]\n",
    "X_test[\"count_chars_nb_mws\"] = pred_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word Embeddings\n",
    "# this function creates a normalized vector for the whole sentence\n",
    "#X_train['sentence_vectors'][0]\n",
    "\n",
    "#foo.columns = ['svd_char_'+str(i) for i in range(n_comp)]\n",
    "X_train = pd.concat([X_train,pd.DataFrame(X_train['sentence_vectors'].tolist())],axis=1)\n",
    "X_test = pd.concat([X_test,pd.DataFrame(X_test['sentence_vectors'].tolist())],axis=1)\n",
    "\n",
    "# xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "# xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]\n",
    "# xtrain_glove = np.array(xtrain_glove)\n",
    "# xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/19579 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16/19579 [00:00<02:12, 147.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 27/19579 [00:00<02:37, 123.78it/s]\u001b[A\n",
      "  0%|          | 42/19579 [00:00<02:30, 129.93it/s]\u001b[A\n",
      "  0%|          | 59/19579 [00:00<02:20, 139.13it/s]\u001b[A\n",
      "  0%|          | 72/19579 [00:00<02:22, 136.52it/s]\u001b[A\n",
      "  0%|          | 89/19579 [00:00<02:17, 141.29it/s]\u001b[A\n",
      "  1%|          | 105/19579 [00:00<02:15, 143.44it/s]\u001b[A\n",
      "  1%|          | 124/19579 [00:00<02:10, 148.54it/s]\u001b[A\n",
      "  1%|          | 140/19579 [00:00<02:11, 147.53it/s]\u001b[A\n",
      "  1%|          | 157/19579 [00:01<02:09, 149.59it/s]\u001b[A\n",
      "  1%|          | 177/19579 [00:01<02:06, 153.17it/s]\u001b[A\n",
      "  1%|          | 194/19579 [00:01<02:06, 153.01it/s]\u001b[A\n",
      "  1%|          | 211/19579 [00:01<02:07, 151.43it/s]\u001b[A\n",
      "  1%|          | 227/19579 [00:01<02:09, 148.94it/s]\u001b[A\n",
      "  1%|▏         | 248/19579 [00:01<02:06, 152.45it/s]\u001b[A\n",
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/16521/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/16521/anaconda2/lib/python2.7/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/16521/anaconda2/lib/python2.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "\n",
      "  1%|▏         | 265/19579 [00:01<02:06, 153.00it/s]\u001b[A\n",
      "  1%|▏         | 285/19579 [00:01<02:04, 154.90it/s]\u001b[A\n",
      "  2%|▏         | 302/19579 [00:01<02:04, 154.99it/s]\u001b[A\n",
      "  2%|▏         | 323/19579 [00:02<02:02, 157.33it/s]\u001b[A\n",
      "  2%|▏         | 344/19579 [00:02<02:00, 159.05it/s]\u001b[A\n",
      "  2%|▏         | 363/19579 [00:02<02:00, 159.22it/s]\u001b[A\n",
      "  2%|▏         | 381/19579 [00:02<02:00, 159.53it/s]\u001b[A\n",
      "  2%|▏         | 399/19579 [00:02<01:59, 159.85it/s]\u001b[A\n",
      "  2%|▏         | 418/19579 [00:02<01:59, 160.75it/s]\u001b[A\n",
      "  2%|▏         | 439/19579 [00:02<01:57, 162.46it/s]\u001b[A\n",
      "  2%|▏         | 459/19579 [00:02<01:57, 163.25it/s]\u001b[A\n",
      "  2%|▏         | 482/19579 [00:02<01:55, 165.05it/s]\u001b[A\n",
      "  3%|▎         | 502/19579 [00:03<01:56, 163.99it/s]\u001b[A\n",
      "  3%|▎         | 520/19579 [00:03<01:56, 163.01it/s]\u001b[A\n",
      "  3%|▎         | 539/19579 [00:03<01:56, 163.83it/s]\u001b[A\n",
      "  3%|▎         | 557/19579 [00:03<01:56, 163.90it/s]\u001b[A\n",
      "  3%|▎         | 575/19579 [00:03<01:56, 163.07it/s]\u001b[A\n",
      "  3%|▎         | 593/19579 [00:03<01:56, 163.45it/s]\u001b[A\n",
      "  3%|▎         | 614/19579 [00:03<01:55, 164.60it/s]\u001b[A\n",
      "  3%|▎         | 633/19579 [00:03<01:54, 165.11it/s]\u001b[A\n",
      "  3%|▎         | 652/19579 [00:03<01:54, 165.49it/s]\u001b[A\n",
      "  3%|▎         | 670/19579 [00:04<01:54, 165.11it/s]\u001b[A\n",
      "  4%|▎         | 688/19579 [00:04<01:54, 165.28it/s]\u001b[A\n",
      "  4%|▎         | 706/19579 [00:04<01:55, 163.50it/s]\u001b[A\n",
      "  4%|▎         | 726/19579 [00:04<01:54, 164.27it/s]\u001b[A\n",
      "  4%|▍         | 743/19579 [00:04<01:54, 164.28it/s]\u001b[A\n",
      "  4%|▍         | 761/19579 [00:04<01:54, 164.50it/s]\u001b[A\n",
      "  4%|▍         | 780/19579 [00:04<01:53, 164.96it/s]\u001b[A\n",
      "  4%|▍         | 798/19579 [00:04<01:54, 164.50it/s]\u001b[A\n",
      "  4%|▍         | 819/19579 [00:04<01:53, 165.00it/s]\u001b[A\n",
      "  4%|▍         | 840/19579 [00:05<01:52, 165.84it/s]\u001b[A\n",
      "  4%|▍         | 861/19579 [00:05<01:52, 166.69it/s]\u001b[A\n",
      "  5%|▍         | 884/19579 [00:05<01:51, 167.75it/s]\u001b[A\n",
      "  5%|▍         | 907/19579 [00:05<01:50, 168.76it/s]\u001b[A\n",
      "  5%|▍         | 928/19579 [00:05<01:50, 168.97it/s]\u001b[A\n",
      "  5%|▍         | 948/19579 [00:05<01:50, 169.05it/s]\u001b[A\n",
      "  5%|▍         | 969/19579 [00:05<01:49, 169.72it/s]\u001b[A\n",
      "  5%|▌         | 989/19579 [00:05<01:49, 169.93it/s]\u001b[A\n",
      "  5%|▌         | 1009/19579 [00:05<01:49, 170.27it/s]\u001b[A\n",
      "  5%|▌         | 1029/19579 [00:06<01:49, 169.81it/s]\u001b[A\n",
      "  5%|▌         | 1049/19579 [00:06<01:48, 170.26it/s]\u001b[A\n",
      "  5%|▌         | 1068/19579 [00:06<01:48, 170.11it/s]\u001b[A\n",
      "  6%|▌         | 1086/19579 [00:06<01:48, 170.20it/s]\u001b[A\n",
      "  6%|▌         | 1104/19579 [00:06<01:48, 170.14it/s]\u001b[A\n",
      "  6%|▌         | 1123/19579 [00:06<01:48, 170.36it/s]\u001b[A\n",
      "  6%|▌         | 1144/19579 [00:06<01:47, 170.83it/s]\u001b[A\n",
      "  6%|▌         | 1164/19579 [00:06<01:47, 171.18it/s]\u001b[A\n",
      "  6%|▌         | 1183/19579 [00:06<01:47, 170.36it/s]\u001b[A\n",
      "  6%|▌         | 1201/19579 [00:07<01:47, 170.27it/s]\u001b[A\n",
      "  6%|▌         | 1222/19579 [00:07<01:47, 170.79it/s]\u001b[A\n",
      "  6%|▋         | 1241/19579 [00:07<01:47, 170.76it/s]\u001b[A\n",
      "  6%|▋         | 1261/19579 [00:07<01:47, 170.95it/s]\u001b[A\n",
      "  7%|▋         | 1279/19579 [00:07<01:47, 170.65it/s]\u001b[A\n",
      "  7%|▋         | 1297/19579 [00:07<01:47, 170.69it/s]\u001b[A\n",
      "  7%|▋         | 1315/19579 [00:07<01:47, 170.12it/s]\u001b[A\n",
      "  7%|▋         | 1332/19579 [00:07<01:47, 169.98it/s]\u001b[A\n",
      "  7%|▋         | 1350/19579 [00:07<01:47, 170.12it/s]\u001b[A\n",
      "  7%|▋         | 1367/19579 [00:08<01:47, 169.98it/s]\u001b[A\n",
      "  7%|▋         | 1384/19579 [00:08<01:47, 169.74it/s]\u001b[A\n",
      "  7%|▋         | 1401/19579 [00:08<01:47, 169.28it/s]\u001b[A\n",
      "  7%|▋         | 1418/19579 [00:08<01:47, 169.30it/s]\u001b[A\n",
      "  7%|▋         | 1437/19579 [00:08<01:47, 169.49it/s]\u001b[A\n",
      "  7%|▋         | 1454/19579 [00:08<01:46, 169.40it/s]\u001b[A\n",
      "  8%|▊         | 1471/19579 [00:08<01:47, 169.12it/s]\u001b[A\n",
      "  8%|▊         | 1488/19579 [00:08<01:47, 168.91it/s]\u001b[A\n",
      "  8%|▊         | 1506/19579 [00:08<01:46, 168.93it/s]\u001b[A\n",
      "  8%|▊         | 1524/19579 [00:09<01:46, 168.97it/s]\u001b[A\n",
      "  8%|▊         | 1541/19579 [00:09<01:46, 168.75it/s]\u001b[A\n",
      "  8%|▊         | 1561/19579 [00:09<01:46, 169.02it/s]\u001b[A\n",
      "  8%|▊         | 1582/19579 [00:09<01:46, 169.35it/s]\u001b[A\n",
      "  8%|▊         | 1600/19579 [00:09<01:46, 169.32it/s]\u001b[A\n",
      "  8%|▊         | 1618/19579 [00:09<01:46, 169.21it/s]\u001b[A\n",
      "  8%|▊         | 1636/19579 [00:09<01:46, 169.03it/s]\u001b[A\n",
      "  8%|▊         | 1655/19579 [00:09<01:46, 169.02it/s]\u001b[A\n",
      "  9%|▊         | 1675/19579 [00:09<01:45, 169.29it/s]\u001b[A\n",
      "  9%|▊         | 1693/19579 [00:10<01:45, 168.74it/s]\u001b[A\n",
      "  9%|▊         | 1711/19579 [00:10<01:45, 168.75it/s]\u001b[A\n",
      "  9%|▉         | 1728/19579 [00:10<01:45, 168.71it/s]\u001b[A\n",
      "  9%|▉         | 1745/19579 [00:10<01:45, 168.63it/s]\u001b[A\n",
      "  9%|▉         | 1763/19579 [00:10<01:45, 168.72it/s]\u001b[A\n",
      "  9%|▉         | 1780/19579 [00:10<01:45, 168.44it/s]\u001b[A\n",
      "  9%|▉         | 1799/19579 [00:10<01:45, 168.44it/s]\u001b[A\n",
      "  9%|▉         | 1816/19579 [00:10<01:45, 168.42it/s]\u001b[A\n",
      "  9%|▉         | 1833/19579 [00:10<01:45, 168.22it/s]\u001b[A\n",
      "  9%|▉         | 1849/19579 [00:11<01:45, 167.70it/s]\u001b[A\n",
      " 10%|▉         | 1867/19579 [00:11<01:45, 167.74it/s]\u001b[A\n",
      " 10%|▉         | 1888/19579 [00:11<01:45, 168.06it/s]\u001b[A\n",
      " 10%|▉         | 1909/19579 [00:11<01:44, 168.38it/s]\u001b[A\n",
      " 10%|▉         | 1929/19579 [00:11<01:44, 168.51it/s]\u001b[A\n",
      " 10%|▉         | 1951/19579 [00:11<01:44, 168.94it/s]\u001b[A\n",
      " 10%|█         | 1971/19579 [00:11<01:44, 169.14it/s]\u001b[A\n",
      " 10%|█         | 1992/19579 [00:11<01:44, 169.08it/s]\u001b[A\n",
      " 10%|█         | 2011/19579 [00:11<01:43, 168.97it/s]\u001b[A\n",
      " 10%|█         | 2029/19579 [00:12<01:43, 168.97it/s]\u001b[A\n",
      " 10%|█         | 2047/19579 [00:12<01:43, 168.85it/s]\u001b[A\n",
      " 11%|█         | 2065/19579 [00:12<01:43, 168.87it/s]\u001b[A\n",
      " 11%|█         | 2083/19579 [00:12<01:43, 168.92it/s]\u001b[A\n",
      " 11%|█         | 2102/19579 [00:12<01:43, 169.04it/s]\u001b[A\n",
      " 11%|█         | 2123/19579 [00:12<01:43, 169.32it/s]\u001b[A\n",
      " 11%|█         | 2142/19579 [00:12<01:43, 169.24it/s]\u001b[A\n",
      " 11%|█         | 2160/19579 [00:12<01:43, 169.03it/s]\u001b[A\n",
      " 11%|█         | 2177/19579 [00:12<01:43, 168.92it/s]\u001b[A\n",
      " 11%|█         | 2196/19579 [00:12<01:42, 169.05it/s]\u001b[A\n",
      " 11%|█▏        | 2218/19579 [00:13<01:42, 169.37it/s]\u001b[A\n",
      " 11%|█▏        | 2239/19579 [00:13<01:42, 169.56it/s]\u001b[A\n",
      " 12%|█▏        | 2258/19579 [00:13<01:42, 169.03it/s]\u001b[A\n",
      " 12%|█▏        | 2275/19579 [00:13<01:42, 168.95it/s]\u001b[A\n",
      " 12%|█▏        | 2292/19579 [00:13<01:42, 168.52it/s]\u001b[A\n",
      " 12%|█▏        | 2314/19579 [00:13<01:42, 168.83it/s]\u001b[A\n",
      " 12%|█▏        | 2332/19579 [00:13<01:42, 168.78it/s]\u001b[A\n",
      " 12%|█▏        | 2353/19579 [00:13<01:41, 169.06it/s]\u001b[A\n",
      " 12%|█▏        | 2372/19579 [00:14<01:41, 169.20it/s]\u001b[A\n",
      " 12%|█▏        | 2391/19579 [00:14<01:41, 169.25it/s]\u001b[A\n",
      " 12%|█▏        | 2414/19579 [00:14<01:41, 169.64it/s]\u001b[A\n",
      " 12%|█▏        | 2434/19579 [00:14<01:41, 169.71it/s]\u001b[A\n",
      " 13%|█▎        | 2454/19579 [00:14<01:40, 169.87it/s]\u001b[A\n",
      " 13%|█▎        | 2473/19579 [00:14<01:40, 169.71it/s]\u001b[A\n",
      " 13%|█▎        | 2493/19579 [00:14<01:40, 169.89it/s]\u001b[A\n",
      " 13%|█▎        | 2513/19579 [00:14<01:40, 170.05it/s]\u001b[A\n",
      " 13%|█▎        | 2532/19579 [00:14<01:40, 169.80it/s]\u001b[A\n",
      " 13%|█▎        | 2550/19579 [00:15<01:40, 169.78it/s]\u001b[A\n",
      " 13%|█▎        | 2570/19579 [00:15<01:40, 169.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2589/19579 [00:15<01:39, 170.09it/s]\u001b[A\n",
      " 13%|█▎        | 2608/19579 [00:15<01:39, 170.04it/s]\u001b[A\n",
      " 13%|█▎        | 2626/19579 [00:15<01:39, 169.69it/s]\u001b[A\n",
      " 14%|█▎        | 2646/19579 [00:15<01:39, 169.85it/s]\u001b[A\n",
      " 14%|█▎        | 2666/19579 [00:15<01:39, 170.03it/s]\u001b[A\n",
      " 14%|█▎        | 2684/19579 [00:15<01:39, 169.98it/s]\u001b[A\n",
      " 14%|█▍        | 2705/19579 [00:15<01:39, 170.21it/s]\u001b[A\n",
      " 14%|█▍        | 2724/19579 [00:16<01:39, 169.78it/s]\u001b[A\n",
      " 14%|█▍        | 2747/19579 [00:16<01:38, 170.13it/s]\u001b[A\n",
      " 14%|█▍        | 2766/19579 [00:16<01:38, 169.99it/s]\u001b[A\n",
      " 14%|█▍        | 2784/19579 [00:16<01:38, 170.01it/s]\u001b[A\n",
      " 14%|█▍        | 2802/19579 [00:16<01:38, 170.05it/s]\u001b[A\n",
      " 14%|█▍        | 2821/19579 [00:16<01:38, 170.15it/s]\u001b[A\n",
      " 15%|█▍        | 2844/19579 [00:16<01:38, 170.40it/s]\u001b[A\n",
      " 15%|█▍        | 2863/19579 [00:16<01:38, 170.40it/s]\u001b[A\n",
      " 15%|█▍        | 2882/19579 [00:16<01:37, 170.44it/s]\u001b[A\n",
      " 15%|█▍        | 2901/19579 [00:17<01:37, 170.54it/s]\u001b[A\n",
      " 15%|█▍        | 2920/19579 [00:17<01:37, 170.30it/s]\u001b[A\n",
      " 15%|█▌        | 2937/19579 [00:17<01:37, 170.10it/s]\u001b[A\n",
      " 15%|█▌        | 2954/19579 [00:17<01:37, 169.94it/s]\u001b[A\n",
      " 15%|█▌        | 2972/19579 [00:17<01:37, 169.93it/s]\u001b[A\n",
      " 15%|█▌        | 2991/19579 [00:17<01:37, 170.05it/s]\u001b[A\n",
      " 15%|█▌        | 3008/19579 [00:17<01:37, 169.94it/s]\u001b[A\n",
      " 15%|█▌        | 3025/19579 [00:17<01:37, 169.88it/s]\u001b[A\n",
      " 16%|█▌        | 3044/19579 [00:17<01:37, 169.96it/s]\u001b[A\n",
      " 16%|█▌        | 3063/19579 [00:18<01:37, 170.02it/s]\u001b[A\n",
      " 16%|█▌        | 3081/19579 [00:18<01:37, 169.93it/s]\u001b[A\n",
      " 16%|█▌        | 3098/19579 [00:18<01:37, 169.82it/s]\u001b[A\n",
      " 16%|█▌        | 3115/19579 [00:18<01:37, 169.70it/s]\u001b[A\n",
      " 16%|█▌        | 3134/19579 [00:18<01:36, 169.80it/s]\u001b[A\n",
      " 16%|█▌        | 3151/19579 [00:18<01:36, 169.71it/s]\u001b[A\n",
      " 16%|█▌        | 3168/19579 [00:18<01:36, 169.53it/s]\u001b[A\n",
      " 16%|█▋        | 3184/19579 [00:18<01:36, 169.42it/s]\u001b[A\n",
      " 16%|█▋        | 3200/19579 [00:18<01:36, 169.25it/s]\u001b[A\n",
      " 16%|█▋        | 3216/19579 [00:19<01:36, 169.07it/s]\u001b[A\n",
      " 17%|█▋        | 3234/19579 [00:19<01:36, 169.10it/s]\u001b[A\n",
      " 17%|█▋        | 3253/19579 [00:19<01:36, 169.17it/s]\u001b[A\n",
      " 17%|█▋        | 3270/19579 [00:19<01:36, 169.16it/s]\u001b[A\n",
      " 17%|█▋        | 3287/19579 [00:19<01:36, 169.02it/s]\u001b[A\n",
      " 17%|█▋        | 3303/19579 [00:19<01:36, 168.95it/s]\u001b[A\n",
      " 17%|█▋        | 3319/19579 [00:19<01:36, 168.91it/s]\u001b[A\n",
      " 17%|█▋        | 3336/19579 [00:19<01:36, 168.90it/s]\u001b[A\n",
      " 17%|█▋        | 3353/19579 [00:19<01:36, 168.89it/s]\u001b[A\n",
      " 17%|█▋        | 3371/19579 [00:19<01:35, 168.84it/s]\u001b[A\n",
      " 17%|█▋        | 3388/19579 [00:20<01:36, 168.50it/s]\u001b[A\n",
      " 17%|█▋        | 3404/19579 [00:20<01:36, 168.45it/s]\u001b[A\n",
      " 17%|█▋        | 3421/19579 [00:20<01:35, 168.41it/s]\u001b[A\n",
      " 18%|█▊        | 3439/19579 [00:20<01:35, 168.43it/s]\u001b[A\n",
      " 18%|█▊        | 3456/19579 [00:20<01:35, 168.14it/s]\u001b[A\n",
      " 18%|█▊        | 3471/19579 [00:20<01:35, 167.99it/s]\u001b[A\n",
      " 18%|█▊        | 3491/19579 [00:20<01:35, 168.15it/s]\u001b[A\n",
      " 18%|█▊        | 3511/19579 [00:20<01:35, 168.29it/s]\u001b[A\n",
      " 18%|█▊        | 3529/19579 [00:20<01:35, 168.06it/s]\u001b[A\n",
      " 18%|█▊        | 3546/19579 [00:21<01:35, 167.69it/s]\u001b[A\n",
      " 18%|█▊        | 3561/19579 [00:21<01:35, 167.61it/s]\u001b[A\n",
      " 18%|█▊        | 3578/19579 [00:21<01:35, 167.59it/s]\u001b[A\n",
      " 18%|█▊        | 3594/19579 [00:21<01:35, 167.50it/s]\u001b[A\n",
      " 18%|█▊        | 3610/19579 [00:21<01:35, 167.42it/s]\u001b[A\n",
      " 19%|█▊        | 3630/19579 [00:21<01:35, 167.52it/s]\u001b[A\n",
      " 19%|█▊        | 3647/19579 [00:21<01:35, 167.52it/s]\u001b[A\n",
      " 19%|█▊        | 3665/19579 [00:21<01:34, 167.56it/s]\u001b[A\n",
      " 19%|█▉        | 3682/19579 [00:21<01:34, 167.51it/s]\u001b[A\n",
      " 19%|█▉        | 3699/19579 [00:22<01:34, 167.44it/s]\u001b[A\n",
      " 19%|█▉        | 3716/19579 [00:22<01:34, 167.27it/s]\u001b[A\n",
      " 19%|█▉        | 3732/19579 [00:22<01:34, 167.17it/s]\u001b[A\n",
      " 19%|█▉        | 3750/19579 [00:22<01:34, 167.23it/s]\u001b[A\n",
      " 19%|█▉        | 3766/19579 [00:22<01:34, 167.17it/s]\u001b[A\n",
      " 19%|█▉        | 3782/19579 [00:22<01:34, 167.13it/s]\u001b[A\n",
      " 19%|█▉        | 3799/19579 [00:22<01:34, 167.11it/s]\u001b[A\n",
      " 19%|█▉        | 3816/19579 [00:22<01:34, 167.10it/s]\u001b[A\n",
      " 20%|█▉        | 3834/19579 [00:22<01:34, 167.14it/s]\u001b[A\n",
      " 20%|█▉        | 3851/19579 [00:23<01:34, 167.05it/s]\u001b[A\n",
      " 20%|█▉        | 3868/19579 [00:23<01:34, 166.87it/s]\u001b[A\n",
      " 20%|█▉        | 3884/19579 [00:23<01:34, 166.77it/s]\u001b[A\n",
      " 20%|█▉        | 3900/19579 [00:23<01:34, 166.69it/s]\u001b[A\n",
      " 20%|██        | 3917/19579 [00:23<01:33, 166.68it/s]\u001b[A\n",
      " 20%|██        | 3933/19579 [00:23<01:33, 166.55it/s]\u001b[A\n",
      " 20%|██        | 3949/19579 [00:23<01:33, 166.50it/s]\u001b[A\n",
      " 20%|██        | 3965/19579 [00:23<01:34, 166.06it/s]\u001b[A\n",
      " 20%|██        | 3979/19579 [00:23<01:34, 165.94it/s]\u001b[A\n",
      " 20%|██        | 3993/19579 [00:24<01:34, 165.80it/s]\u001b[A\n",
      " 20%|██        | 4009/19579 [00:24<01:33, 165.78it/s]\u001b[A\n",
      " 21%|██        | 4026/19579 [00:24<01:33, 165.78it/s]\u001b[A\n",
      " 21%|██        | 4043/19579 [00:24<01:33, 165.69it/s]\u001b[A\n",
      " 21%|██        | 4058/19579 [00:24<01:33, 165.62it/s]\u001b[A\n",
      " 21%|██        | 4073/19579 [00:24<01:33, 165.54it/s]\u001b[A\n",
      " 21%|██        | 4091/19579 [00:24<01:33, 165.53it/s]\u001b[A\n",
      " 21%|██        | 4110/19579 [00:24<01:33, 165.61it/s]\u001b[A\n",
      " 21%|██        | 4127/19579 [00:24<01:33, 165.43it/s]\u001b[A\n",
      " 21%|██        | 4146/19579 [00:25<01:33, 165.48it/s]\u001b[A\n",
      " 21%|██▏       | 4162/19579 [00:25<01:33, 165.45it/s]\u001b[A\n",
      " 21%|██▏       | 4178/19579 [00:25<01:33, 165.37it/s]\u001b[A\n",
      " 21%|██▏       | 4194/19579 [00:25<01:33, 165.03it/s]\u001b[A\n",
      " 22%|██▏       | 4210/19579 [00:25<01:33, 165.00it/s]\u001b[A\n",
      " 22%|██▏       | 4228/19579 [00:25<01:33, 165.03it/s]\u001b[A\n",
      " 22%|██▏       | 4247/19579 [00:25<01:32, 165.10it/s]\u001b[A\n",
      " 22%|██▏       | 4264/19579 [00:25<01:32, 165.04it/s]\u001b[A\n",
      " 22%|██▏       | 4280/19579 [00:25<01:32, 165.01it/s]\u001b[A\n",
      " 22%|██▏       | 4298/19579 [00:26<01:32, 165.05it/s]\u001b[A\n",
      " 22%|██▏       | 4315/19579 [00:26<01:32, 165.04it/s]\u001b[A\n",
      " 22%|██▏       | 4332/19579 [00:26<01:32, 164.98it/s]\u001b[A\n",
      " 22%|██▏       | 4348/19579 [00:26<01:32, 164.87it/s]\u001b[A\n",
      " 22%|██▏       | 4364/19579 [00:26<01:32, 164.72it/s]\u001b[A\n",
      " 22%|██▏       | 4379/19579 [00:26<01:32, 164.62it/s]\u001b[A\n",
      " 22%|██▏       | 4394/19579 [00:26<01:32, 164.49it/s]\u001b[A\n",
      " 23%|██▎       | 4414/19579 [00:26<01:32, 164.62it/s]\u001b[A\n",
      " 23%|██▎       | 4431/19579 [00:26<01:32, 164.62it/s]\u001b[A\n",
      " 23%|██▎       | 4448/19579 [00:27<01:31, 164.61it/s]\u001b[A\n",
      " 23%|██▎       | 4470/19579 [00:27<01:31, 164.81it/s]\u001b[A\n",
      " 23%|██▎       | 4488/19579 [00:27<01:31, 164.77it/s]\u001b[A\n",
      " 23%|██▎       | 4506/19579 [00:27<01:31, 164.58it/s]\u001b[A\n",
      " 23%|██▎       | 4522/19579 [00:27<01:31, 164.51it/s]\u001b[A\n",
      " 23%|██▎       | 4540/19579 [00:27<01:31, 164.52it/s]\u001b[A\n",
      " 23%|██▎       | 4557/19579 [00:27<01:31, 164.50it/s]\u001b[A\n",
      " 23%|██▎       | 4577/19579 [00:27<01:31, 164.61it/s]\u001b[A\n",
      " 23%|██▎       | 4599/19579 [00:27<01:30, 164.81it/s]\u001b[A\n",
      " 24%|██▎       | 4618/19579 [00:28<01:30, 164.85it/s]\u001b[A\n",
      " 24%|██▎       | 4637/19579 [00:28<01:30, 164.87it/s]\u001b[A\n",
      " 24%|██▍       | 4655/19579 [00:28<01:30, 164.84it/s]\u001b[A\n",
      " 24%|██▍       | 4673/19579 [00:28<01:30, 164.45it/s]\u001b[A\n",
      " 24%|██▍       | 4689/19579 [00:28<01:30, 164.19it/s]\u001b[A\n",
      " 24%|██▍       | 4703/19579 [00:28<01:30, 164.11it/s]\u001b[A\n",
      " 24%|██▍       | 4717/19579 [00:28<01:30, 164.01it/s]\u001b[A\n",
      " 24%|██▍       | 4735/19579 [00:28<01:30, 164.05it/s]\u001b[A\n",
      " 24%|██▍       | 4751/19579 [00:28<01:30, 164.00it/s]\u001b[A\n",
      " 24%|██▍       | 4767/19579 [00:29<01:30, 163.61it/s]\u001b[A\n",
      " 24%|██▍       | 4781/19579 [00:29<01:30, 163.44it/s]\u001b[A\n",
      " 25%|██▍       | 4798/19579 [00:29<01:30, 163.42it/s]\u001b[A\n",
      " 25%|██▍       | 4812/19579 [00:29<01:30, 163.33it/s]\u001b[A\n",
      " 25%|██▍       | 4828/19579 [00:29<01:30, 163.31it/s]\u001b[A\n",
      " 25%|██▍       | 4843/19579 [00:29<01:30, 163.25it/s]\u001b[A\n",
      " 25%|██▍       | 4858/19579 [00:29<01:30, 163.00it/s]\u001b[A\n",
      " 25%|██▍       | 4872/19579 [00:29<01:30, 162.70it/s]\u001b[A\n",
      " 25%|██▍       | 4887/19579 [00:30<01:30, 162.66it/s]\u001b[A\n",
      " 25%|██▌       | 4904/19579 [00:30<01:30, 162.65it/s]\u001b[A\n",
      " 25%|██▌       | 4919/19579 [00:30<01:30, 162.55it/s]\u001b[A\n",
      " 25%|██▌       | 4933/19579 [00:30<01:30, 162.11it/s]\u001b[A\n",
      " 25%|██▌       | 4952/19579 [00:30<01:30, 162.17it/s]\u001b[A\n",
      " 25%|██▌       | 4972/19579 [00:30<01:30, 162.28it/s]\u001b[A\n",
      " 25%|██▌       | 4989/19579 [00:30<01:29, 162.30it/s]\u001b[A\n",
      " 26%|██▌       | 5005/19579 [00:30<01:29, 162.28it/s]\u001b[A\n",
      " 26%|██▌       | 5021/19579 [00:30<01:29, 162.24it/s]\u001b[A\n",
      " 26%|██▌       | 5037/19579 [00:31<01:29, 162.18it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5057/19579 [00:31<01:29, 162.27it/s]\u001b[A\n",
      " 26%|██▌       | 5074/19579 [00:31<01:29, 162.11it/s]\u001b[A\n",
      " 26%|██▌       | 5090/19579 [00:31<01:29, 162.08it/s]\u001b[A\n",
      " 26%|██▌       | 5106/19579 [00:31<01:29, 161.99it/s]\u001b[A\n",
      " 26%|██▌       | 5121/19579 [00:31<01:29, 161.78it/s]\u001b[A\n",
      " 26%|██▌       | 5139/19579 [00:31<01:29, 161.75it/s]\u001b[A\n",
      " 26%|██▋       | 5154/19579 [00:31<01:29, 161.68it/s]\u001b[A\n",
      " 26%|██▋       | 5169/19579 [00:31<01:29, 161.54it/s]\u001b[A\n",
      " 26%|██▋       | 5183/19579 [00:32<01:29, 161.45it/s]\u001b[A\n",
      " 27%|██▋       | 5202/19579 [00:32<01:29, 161.51it/s]\u001b[A\n",
      " 27%|██▋       | 5217/19579 [00:32<01:28, 161.39it/s]\u001b[A\n",
      " 27%|██▋       | 5233/19579 [00:32<01:28, 161.35it/s]\u001b[A\n",
      " 27%|██▋       | 5248/19579 [00:32<01:28, 161.31it/s]\u001b[A\n",
      " 27%|██▋       | 5263/19579 [00:32<01:28, 161.26it/s]\u001b[A\n",
      " 27%|██▋       | 5279/19579 [00:32<01:28, 161.23it/s]\u001b[A\n",
      " 27%|██▋       | 5294/19579 [00:32<01:28, 161.18it/s]\u001b[A\n",
      " 27%|██▋       | 5309/19579 [00:32<01:28, 161.11it/s]\u001b[A\n",
      " 27%|██▋       | 5326/19579 [00:33<01:28, 161.11it/s]\u001b[A\n",
      " 27%|██▋       | 5341/19579 [00:33<01:28, 160.87it/s]\u001b[A\n",
      " 27%|██▋       | 5355/19579 [00:33<01:28, 160.69it/s]\u001b[A\n",
      " 27%|██▋       | 5372/19579 [00:33<01:28, 160.70it/s]\u001b[A\n",
      " 28%|██▊       | 5394/19579 [00:33<01:28, 160.87it/s]\u001b[A\n",
      " 28%|██▊       | 5414/19579 [00:33<01:28, 160.96it/s]\u001b[A\n",
      " 28%|██▊       | 5432/19579 [00:33<01:27, 160.97it/s]\u001b[A\n",
      " 28%|██▊       | 5451/19579 [00:33<01:27, 161.03it/s]\u001b[A\n",
      " 28%|██▊       | 5469/19579 [00:33<01:27, 161.06it/s]\u001b[A\n",
      " 28%|██▊       | 5487/19579 [00:34<01:27, 160.99it/s]\u001b[A\n",
      " 28%|██▊       | 5504/19579 [00:34<01:27, 160.90it/s]\u001b[A\n",
      " 28%|██▊       | 5521/19579 [00:34<01:27, 160.92it/s]\u001b[A\n",
      " 28%|██▊       | 5540/19579 [00:34<01:27, 160.96it/s]\u001b[A\n",
      " 28%|██▊       | 5557/19579 [00:34<01:27, 160.85it/s]\u001b[A\n",
      " 28%|██▊       | 5574/19579 [00:34<01:27, 160.85it/s]\u001b[A\n",
      " 29%|██▊       | 5590/19579 [00:34<01:27, 160.74it/s]\u001b[A\n",
      " 29%|██▊       | 5608/19579 [00:34<01:26, 160.80it/s]\u001b[A\n",
      " 29%|██▊       | 5625/19579 [00:34<01:26, 160.79it/s]\u001b[A\n",
      " 29%|██▉       | 5641/19579 [00:35<01:26, 160.72it/s]\u001b[A\n",
      " 29%|██▉       | 5660/19579 [00:35<01:26, 160.79it/s]\u001b[A\n",
      " 29%|██▉       | 5677/19579 [00:35<01:26, 160.77it/s]\u001b[A\n",
      " 29%|██▉       | 5693/19579 [00:35<01:26, 160.62it/s]\u001b[A\n",
      " 29%|██▉       | 5710/19579 [00:35<01:26, 160.64it/s]\u001b[A\n",
      " 29%|██▉       | 5727/19579 [00:35<01:26, 160.61it/s]\u001b[A\n",
      " 29%|██▉       | 5745/19579 [00:35<01:26, 160.65it/s]\u001b[A\n",
      " 29%|██▉       | 5763/19579 [00:35<01:25, 160.70it/s]\u001b[A\n",
      " 30%|██▉       | 5780/19579 [00:36<01:25, 160.48it/s]\u001b[A\n",
      " 30%|██▉       | 5795/19579 [00:36<01:25, 160.32it/s]\u001b[A\n",
      " 30%|██▉       | 5809/19579 [00:36<01:25, 160.21it/s]\u001b[A\n",
      " 30%|██▉       | 5824/19579 [00:36<01:25, 160.17it/s]\u001b[A\n",
      " 30%|██▉       | 5839/19579 [00:36<01:25, 160.14it/s]\u001b[A\n",
      " 30%|██▉       | 5863/19579 [00:36<01:25, 160.32it/s]\u001b[A\n",
      " 30%|███       | 5880/19579 [00:36<01:25, 160.33it/s]\u001b[A\n",
      " 30%|███       | 5898/19579 [00:36<01:25, 160.36it/s]\u001b[A\n",
      " 30%|███       | 5918/19579 [00:36<01:25, 160.45it/s]\u001b[A\n",
      " 30%|███       | 5936/19579 [00:37<01:25, 160.39it/s]\u001b[A\n",
      " 30%|███       | 5953/19579 [00:37<01:24, 160.39it/s]\u001b[A\n",
      " 30%|███       | 5970/19579 [00:37<01:24, 160.41it/s]\u001b[A\n",
      " 31%|███       | 5987/19579 [00:37<01:24, 160.39it/s]\u001b[A\n",
      " 31%|███       | 6004/19579 [00:37<01:24, 160.26it/s]\u001b[A\n",
      " 31%|███       | 6020/19579 [00:37<01:24, 160.17it/s]\u001b[A\n",
      " 31%|███       | 6037/19579 [00:37<01:24, 160.15it/s]\u001b[A\n",
      " 31%|███       | 6054/19579 [00:37<01:24, 160.16it/s]\u001b[A\n",
      " 31%|███       | 6070/19579 [00:37<01:24, 160.13it/s]\u001b[A\n",
      " 31%|███       | 6090/19579 [00:38<01:24, 160.22it/s]\u001b[A\n",
      " 31%|███       | 6107/19579 [00:38<01:24, 160.17it/s]\u001b[A\n",
      " 31%|███▏      | 6126/19579 [00:38<01:23, 160.25it/s]\u001b[A\n",
      " 31%|███▏      | 6143/19579 [00:38<01:23, 160.22it/s]\u001b[A\n",
      " 31%|███▏      | 6161/19579 [00:38<01:23, 160.26it/s]\u001b[A\n",
      " 32%|███▏      | 6178/19579 [00:38<01:23, 160.21it/s]\u001b[A\n",
      " 32%|███▏      | 6194/19579 [00:38<01:23, 160.12it/s]\u001b[A\n",
      " 32%|███▏      | 6210/19579 [00:38<01:23, 160.08it/s]\u001b[A\n",
      " 32%|███▏      | 6227/19579 [00:38<01:23, 160.10it/s]\u001b[A\n",
      " 32%|███▏      | 6245/19579 [00:38<01:23, 160.14it/s]\u001b[A\n",
      " 32%|███▏      | 6263/19579 [00:39<01:23, 160.19it/s]\u001b[A\n",
      " 32%|███▏      | 6280/19579 [00:39<01:23, 160.17it/s]\u001b[A\n",
      " 32%|███▏      | 6302/19579 [00:39<01:22, 160.30it/s]\u001b[A\n",
      " 32%|███▏      | 6323/19579 [00:39<01:22, 160.36it/s]\u001b[A\n",
      " 32%|███▏      | 6344/19579 [00:39<01:22, 160.47it/s]\u001b[A\n",
      " 32%|███▏      | 6363/19579 [00:39<01:22, 160.38it/s]\u001b[A\n",
      " 33%|███▎      | 6381/19579 [00:39<01:22, 160.33it/s]\u001b[A\n",
      " 33%|███▎      | 6398/19579 [00:39<01:22, 160.35it/s]\u001b[A\n",
      " 33%|███▎      | 6420/19579 [00:40<01:21, 160.49it/s]\u001b[A\n",
      " 33%|███▎      | 6438/19579 [00:40<01:21, 160.46it/s]\u001b[A\n",
      " 33%|███▎      | 6456/19579 [00:40<01:21, 160.45it/s]\u001b[A\n",
      " 33%|███▎      | 6473/19579 [00:40<01:21, 160.47it/s]\u001b[A\n",
      " 33%|███▎      | 6490/19579 [00:40<01:21, 160.47it/s]\u001b[A\n",
      " 33%|███▎      | 6507/19579 [00:40<01:21, 160.43it/s]\u001b[A\n",
      " 33%|███▎      | 6523/19579 [00:40<01:21, 160.39it/s]\u001b[A\n",
      " 33%|███▎      | 6542/19579 [00:40<01:21, 160.44it/s]\u001b[A\n",
      " 34%|███▎      | 6559/19579 [00:40<01:21, 160.44it/s]\u001b[A\n",
      " 34%|███▎      | 6576/19579 [00:40<01:21, 160.44it/s]\u001b[A\n",
      " 34%|███▎      | 6593/19579 [00:41<01:20, 160.41it/s]\u001b[A\n",
      " 34%|███▍      | 6613/19579 [00:41<01:20, 160.51it/s]\u001b[A\n",
      " 34%|███▍      | 6634/19579 [00:41<01:20, 160.61it/s]\u001b[A\n",
      " 34%|███▍      | 6652/19579 [00:41<01:20, 160.65it/s]\u001b[A\n",
      " 34%|███▍      | 6670/19579 [00:41<01:20, 160.69it/s]\u001b[A\n",
      " 34%|███▍      | 6688/19579 [00:41<01:20, 160.68it/s]\u001b[A\n",
      " 34%|███▍      | 6706/19579 [00:41<01:20, 160.65it/s]\u001b[A\n",
      " 34%|███▍      | 6724/19579 [00:41<01:20, 160.65it/s]\u001b[A\n",
      " 34%|███▍      | 6743/19579 [00:41<01:19, 160.68it/s]\u001b[A\n",
      " 35%|███▍      | 6762/19579 [00:42<01:19, 160.74it/s]\u001b[A\n",
      " 35%|███▍      | 6784/19579 [00:42<01:19, 160.86it/s]\u001b[A\n",
      " 35%|███▍      | 6804/19579 [00:42<01:19, 160.93it/s]\u001b[A\n",
      " 35%|███▍      | 6823/19579 [00:42<01:19, 160.92it/s]\u001b[A\n",
      " 35%|███▍      | 6841/19579 [00:42<01:19, 160.91it/s]\u001b[A\n",
      " 35%|███▌      | 6859/19579 [00:42<01:19, 160.92it/s]\u001b[A\n",
      " 35%|███▌      | 6876/19579 [00:42<01:18, 160.89it/s]\u001b[A\n",
      " 35%|███▌      | 6896/19579 [00:42<01:18, 160.96it/s]\u001b[A\n",
      " 35%|███▌      | 6916/19579 [00:42<01:18, 161.04it/s]\u001b[A\n",
      " 35%|███▌      | 6934/19579 [00:43<01:18, 161.01it/s]\u001b[A\n",
      " 36%|███▌      | 6952/19579 [00:43<01:18, 161.04it/s]\u001b[A\n",
      " 36%|███▌      | 6974/19579 [00:43<01:18, 161.14it/s]\u001b[A\n",
      " 36%|███▌      | 6992/19579 [00:43<01:18, 161.12it/s]\u001b[A\n",
      " 36%|███▌      | 7010/19579 [00:43<01:18, 161.09it/s]\u001b[A\n",
      " 36%|███▌      | 7027/19579 [00:43<01:17, 161.06it/s]\u001b[A\n",
      " 36%|███▌      | 7046/19579 [00:43<01:17, 161.10it/s]\u001b[A\n",
      " 36%|███▌      | 7063/19579 [00:43<01:17, 161.10it/s]\u001b[A\n",
      " 36%|███▌      | 7081/19579 [00:43<01:17, 161.12it/s]\u001b[A\n",
      " 36%|███▋      | 7103/19579 [00:44<01:17, 161.24it/s]\u001b[A\n",
      " 36%|███▋      | 7121/19579 [00:44<01:17, 161.24it/s]\u001b[A\n",
      " 36%|███▋      | 7139/19579 [00:44<01:17, 161.27it/s]\u001b[A\n",
      " 37%|███▋      | 7157/19579 [00:44<01:17, 161.22it/s]\u001b[A\n",
      " 37%|███▋      | 7174/19579 [00:44<01:16, 161.17it/s]\u001b[A\n",
      " 37%|███▋      | 7196/19579 [00:44<01:16, 161.29it/s]\u001b[A\n",
      " 37%|███▋      | 7218/19579 [00:44<01:16, 161.40it/s]\u001b[A\n",
      " 37%|███▋      | 7237/19579 [00:44<01:16, 161.40it/s]\u001b[A\n",
      " 37%|███▋      | 7256/19579 [00:44<01:16, 161.44it/s]\u001b[A\n",
      " 37%|███▋      | 7277/19579 [00:45<01:16, 161.54it/s]\u001b[A\n",
      " 37%|███▋      | 7297/19579 [00:45<01:15, 161.62it/s]\u001b[A\n",
      " 37%|███▋      | 7316/19579 [00:45<01:15, 161.63it/s]\u001b[A\n",
      " 37%|███▋      | 7335/19579 [00:45<01:15, 161.68it/s]\u001b[A\n",
      " 38%|███▊      | 7356/19579 [00:45<01:15, 161.77it/s]\u001b[A\n",
      " 38%|███▊      | 7375/19579 [00:45<01:15, 161.79it/s]\u001b[A\n",
      " 38%|███▊      | 7394/19579 [00:45<01:15, 161.80it/s]\u001b[A\n",
      " 38%|███▊      | 7413/19579 [00:45<01:15, 161.85it/s]\u001b[A\n",
      " 38%|███▊      | 7432/19579 [00:45<01:15, 161.90it/s]\u001b[A\n",
      " 38%|███▊      | 7451/19579 [00:46<01:14, 161.96it/s]\u001b[A\n",
      " 38%|███▊      | 7470/19579 [00:46<01:14, 161.90it/s]\u001b[A\n",
      " 38%|███▊      | 7489/19579 [00:46<01:14, 161.96it/s]\u001b[A\n",
      " 38%|███▊      | 7508/19579 [00:46<01:14, 162.01it/s]\u001b[A\n",
      " 38%|███▊      | 7526/19579 [00:46<01:14, 162.00it/s]\u001b[A\n",
      " 39%|███▊      | 7547/19579 [00:46<01:14, 162.09it/s]\u001b[A\n",
      " 39%|███▊      | 7566/19579 [00:46<01:14, 162.11it/s]\u001b[A\n",
      " 39%|███▊      | 7584/19579 [00:46<01:13, 162.12it/s]\u001b[A\n",
      " 39%|███▉      | 7602/19579 [00:46<01:13, 162.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7620/19579 [00:47<01:13, 162.12it/s]\u001b[A\n",
      " 39%|███▉      | 7638/19579 [00:47<01:13, 162.15it/s]\u001b[A\n",
      " 39%|███▉      | 7656/19579 [00:47<01:13, 162.18it/s]\u001b[A\n",
      " 39%|███▉      | 7676/19579 [00:47<01:13, 162.26it/s]\u001b[A\n",
      " 39%|███▉      | 7699/19579 [00:47<01:13, 162.39it/s]\u001b[A\n",
      " 39%|███▉      | 7719/19579 [00:47<01:13, 162.42it/s]\u001b[A\n",
      " 40%|███▉      | 7738/19579 [00:47<01:12, 162.37it/s]\u001b[A\n",
      " 40%|███▉      | 7756/19579 [00:47<01:12, 162.37it/s]\u001b[A\n",
      " 40%|███▉      | 7774/19579 [00:47<01:12, 162.36it/s]\u001b[A\n",
      " 40%|███▉      | 7791/19579 [00:47<01:12, 162.37it/s]\u001b[A\n",
      " 40%|███▉      | 7808/19579 [00:48<01:12, 162.34it/s]\u001b[A\n",
      " 40%|███▉      | 7825/19579 [00:48<01:12, 162.32it/s]\u001b[A\n",
      " 40%|████      | 7841/19579 [00:48<01:12, 162.27it/s]\u001b[A\n",
      " 40%|████      | 7862/19579 [00:48<01:12, 162.37it/s]\u001b[A\n",
      " 40%|████      | 7880/19579 [00:48<01:12, 162.39it/s]\u001b[A\n",
      " 40%|████      | 7899/19579 [00:48<01:11, 162.44it/s]\u001b[A\n",
      " 40%|████      | 7917/19579 [00:48<01:11, 162.40it/s]\u001b[A\n",
      " 41%|████      | 7934/19579 [00:48<01:11, 162.32it/s]\u001b[A\n",
      " 41%|████      | 7950/19579 [00:48<01:11, 162.29it/s]\u001b[A\n",
      " 41%|████      | 7968/19579 [00:49<01:11, 162.32it/s]\u001b[A\n",
      " 41%|████      | 7985/19579 [00:49<01:11, 162.28it/s]\u001b[A\n",
      " 41%|████      | 8001/19579 [00:49<01:11, 162.26it/s]\u001b[A\n",
      " 41%|████      | 8017/19579 [00:49<01:11, 162.25it/s]\u001b[A\n",
      " 41%|████      | 8035/19579 [00:49<01:11, 162.28it/s]\u001b[A\n",
      " 41%|████      | 8058/19579 [00:49<01:10, 162.40it/s]\u001b[A\n",
      " 41%|████      | 8076/19579 [00:49<01:10, 162.42it/s]\u001b[A\n",
      " 41%|████▏     | 8094/19579 [00:49<01:10, 162.45it/s]\u001b[A\n",
      " 41%|████▏     | 8114/19579 [00:49<01:10, 162.49it/s]\u001b[A\n",
      " 42%|████▏     | 8134/19579 [00:50<01:10, 162.55it/s]\u001b[A\n",
      " 42%|████▏     | 8153/19579 [00:50<01:10, 162.60it/s]\u001b[A\n",
      " 42%|████▏     | 8172/19579 [00:50<01:10, 162.64it/s]\u001b[A\n",
      " 42%|████▏     | 8191/19579 [00:50<01:10, 162.67it/s]\u001b[A\n",
      " 42%|████▏     | 8210/19579 [00:50<01:09, 162.68it/s]\u001b[A\n",
      " 42%|████▏     | 8230/19579 [00:50<01:09, 162.74it/s]\u001b[A\n",
      " 42%|████▏     | 8249/19579 [00:50<01:09, 162.75it/s]\u001b[A\n",
      " 42%|████▏     | 8267/19579 [00:50<01:09, 162.73it/s]\u001b[A\n",
      " 42%|████▏     | 8285/19579 [00:50<01:09, 162.68it/s]\u001b[A\n",
      " 42%|████▏     | 8302/19579 [00:51<01:09, 162.64it/s]\u001b[A\n",
      " 43%|████▎     | 8328/19579 [00:51<01:09, 162.81it/s]\u001b[A\n",
      " 43%|████▎     | 8347/19579 [00:51<01:09, 162.76it/s]\u001b[A\n",
      " 43%|████▎     | 8369/19579 [00:51<01:08, 162.86it/s]\u001b[A\n",
      " 43%|████▎     | 8389/19579 [00:51<01:08, 162.91it/s]\u001b[A\n",
      " 43%|████▎     | 8408/19579 [00:51<01:08, 162.96it/s]\u001b[A\n",
      " 43%|████▎     | 8427/19579 [00:51<01:08, 162.98it/s]\u001b[A\n",
      " 43%|████▎     | 8446/19579 [00:51<01:08, 162.95it/s]\u001b[A\n",
      " 43%|████▎     | 8470/19579 [00:51<01:08, 163.08it/s]\u001b[A\n",
      " 43%|████▎     | 8491/19579 [00:52<01:07, 163.15it/s]\u001b[A\n",
      " 43%|████▎     | 8511/19579 [00:52<01:07, 163.13it/s]\u001b[A\n",
      " 44%|████▎     | 8530/19579 [00:52<01:07, 163.17it/s]\u001b[A\n",
      " 44%|████▎     | 8549/19579 [00:52<01:07, 163.15it/s]\u001b[A\n",
      " 44%|████▍     | 8569/19579 [00:52<01:07, 163.20it/s]\u001b[A\n",
      " 44%|████▍     | 8587/19579 [00:52<01:07, 163.22it/s]\u001b[A\n",
      " 44%|████▍     | 8609/19579 [00:52<01:07, 163.33it/s]\u001b[A\n",
      " 44%|████▍     | 8631/19579 [00:52<01:06, 163.43it/s]\u001b[A\n",
      " 44%|████▍     | 8651/19579 [00:52<01:06, 163.45it/s]\u001b[A\n",
      " 44%|████▍     | 8671/19579 [00:53<01:06, 163.52it/s]\u001b[A\n",
      " 44%|████▍     | 8692/19579 [00:53<01:06, 163.60it/s]\u001b[A\n",
      " 44%|████▍     | 8712/19579 [00:53<01:06, 163.57it/s]\u001b[A\n",
      " 45%|████▍     | 8731/19579 [00:53<01:06, 163.58it/s]\u001b[A\n",
      " 45%|████▍     | 8749/19579 [00:53<01:06, 163.59it/s]\u001b[A\n",
      " 45%|████▍     | 8769/19579 [00:53<01:06, 163.65it/s]\u001b[A\n",
      " 45%|████▍     | 8788/19579 [00:53<01:05, 163.64it/s]\u001b[A\n",
      " 45%|████▍     | 8807/19579 [00:53<01:05, 163.68it/s]\u001b[A\n",
      " 45%|████▌     | 8828/19579 [00:53<01:05, 163.76it/s]\u001b[A\n",
      " 45%|████▌     | 8847/19579 [00:54<01:05, 163.79it/s]\u001b[A\n",
      " 45%|████▌     | 8871/19579 [00:54<01:05, 163.92it/s]\u001b[A\n",
      " 45%|████▌     | 8892/19579 [00:54<01:05, 164.00it/s]\u001b[A\n",
      " 46%|████▌     | 8913/19579 [00:54<01:05, 164.02it/s]\u001b[A\n",
      " 46%|████▌     | 8933/19579 [00:54<01:04, 164.04it/s]\u001b[A\n",
      " 46%|████▌     | 8954/19579 [00:54<01:04, 164.11it/s]\u001b[A\n",
      " 46%|████▌     | 8974/19579 [00:54<01:04, 164.10it/s]\u001b[A\n",
      " 46%|████▌     | 8993/19579 [00:54<01:04, 164.04it/s]\u001b[A\n",
      " 46%|████▌     | 9010/19579 [00:54<01:04, 164.03it/s]\u001b[A\n",
      " 46%|████▌     | 9028/19579 [00:55<01:04, 164.05it/s]\u001b[A\n",
      " 46%|████▌     | 9045/19579 [00:55<01:04, 164.02it/s]\u001b[A\n",
      " 46%|████▋     | 9069/19579 [00:55<01:04, 164.13it/s]\u001b[A\n",
      " 46%|████▋     | 9088/19579 [00:55<01:03, 164.18it/s]\u001b[A\n",
      " 47%|████▋     | 9107/19579 [00:55<01:03, 164.13it/s]\u001b[A\n",
      " 47%|████▋     | 9127/19579 [00:55<01:03, 164.19it/s]\u001b[A\n",
      " 47%|████▋     | 9147/19579 [00:55<01:03, 164.24it/s]\u001b[A\n",
      " 47%|████▋     | 9166/19579 [00:55<01:03, 164.21it/s]\u001b[A\n",
      " 47%|████▋     | 9185/19579 [00:55<01:03, 164.26it/s]\u001b[A\n",
      " 47%|████▋     | 9208/19579 [00:56<01:03, 164.36it/s]\u001b[A\n",
      " 47%|████▋     | 9228/19579 [00:56<01:03, 163.92it/s]\u001b[A\n",
      " 47%|████▋     | 9246/19579 [00:56<01:03, 163.94it/s]\u001b[A\n",
      " 47%|████▋     | 9265/19579 [00:56<01:02, 163.96it/s]\u001b[A\n",
      " 47%|████▋     | 9282/19579 [00:56<01:02, 163.94it/s]\u001b[A\n",
      " 47%|████▋     | 9299/19579 [00:56<01:02, 163.92it/s]\u001b[A\n",
      " 48%|████▊     | 9316/19579 [00:56<01:02, 163.92it/s]\u001b[A\n",
      " 48%|████▊     | 9333/19579 [00:56<01:02, 163.91it/s]\u001b[A\n",
      " 48%|████▊     | 9350/19579 [00:57<01:02, 163.84it/s]\u001b[A\n",
      " 48%|████▊     | 9367/19579 [00:57<01:02, 163.84it/s]\u001b[A\n",
      " 48%|████▊     | 9388/19579 [00:57<01:02, 163.91it/s]\u001b[A\n",
      " 48%|████▊     | 9407/19579 [00:57<01:02, 163.90it/s]\u001b[A\n",
      " 48%|████▊     | 9424/19579 [00:57<01:01, 163.88it/s]\u001b[A\n",
      " 48%|████▊     | 9444/19579 [00:57<01:01, 163.94it/s]\u001b[A\n",
      " 48%|████▊     | 9462/19579 [00:57<01:01, 163.96it/s]\u001b[A\n",
      " 48%|████▊     | 9480/19579 [00:57<01:01, 163.97it/s]\u001b[A\n",
      " 49%|████▊     | 9498/19579 [00:57<01:01, 163.94it/s]\u001b[A\n",
      " 49%|████▊     | 9515/19579 [00:58<01:01, 163.92it/s]\u001b[A\n",
      " 49%|████▊     | 9532/19579 [00:58<01:01, 163.92it/s]\u001b[A\n",
      " 49%|████▉     | 9553/19579 [00:58<01:01, 163.98it/s]\u001b[A\n",
      " 49%|████▉     | 9572/19579 [00:58<01:01, 164.00it/s]\u001b[A\n",
      " 49%|████▉     | 9590/19579 [00:58<01:00, 164.01it/s]\u001b[A\n",
      " 49%|████▉     | 9609/19579 [00:58<01:00, 164.03it/s]\u001b[A\n",
      " 49%|████▉     | 9628/19579 [00:58<01:00, 164.07it/s]\u001b[A\n",
      " 49%|████▉     | 9646/19579 [00:58<01:00, 164.09it/s]\u001b[A\n",
      " 49%|████▉     | 9668/19579 [00:58<01:00, 164.18it/s]\u001b[A\n",
      " 49%|████▉     | 9688/19579 [00:58<01:00, 164.23it/s]\u001b[A\n",
      " 50%|████▉     | 9711/19579 [00:59<01:00, 164.33it/s]\u001b[A\n",
      " 50%|████▉     | 9731/19579 [00:59<00:59, 164.35it/s]\u001b[A\n",
      " 50%|████▉     | 9751/19579 [00:59<00:59, 164.31it/s]\u001b[A\n",
      " 50%|████▉     | 9769/19579 [00:59<00:59, 164.31it/s]\u001b[A\n",
      " 50%|█████     | 9792/19579 [00:59<00:59, 164.40it/s]\u001b[A\n",
      " 50%|█████     | 9811/19579 [00:59<00:59, 164.42it/s]\u001b[A\n",
      " 50%|█████     | 9830/19579 [00:59<00:59, 164.40it/s]\u001b[A\n",
      " 50%|█████     | 9848/19579 [00:59<00:59, 164.42it/s]\u001b[A\n",
      " 50%|█████     | 9867/19579 [00:59<00:59, 164.45it/s]\u001b[A\n",
      " 50%|█████     | 9886/19579 [01:00<00:58, 164.49it/s]\u001b[A\n",
      " 51%|█████     | 9911/19579 [01:00<00:58, 164.62it/s]\u001b[A\n",
      " 51%|█████     | 9931/19579 [01:00<00:58, 164.62it/s]\u001b[A\n",
      " 51%|█████     | 9950/19579 [01:00<00:58, 164.63it/s]\u001b[A\n",
      " 51%|█████     | 9970/19579 [01:00<00:58, 164.68it/s]\u001b[A\n",
      " 51%|█████     | 9989/19579 [01:00<00:58, 164.59it/s]\u001b[A\n",
      " 51%|█████     | 10006/19579 [01:00<00:58, 164.57it/s]\u001b[A\n",
      " 51%|█████     | 10030/19579 [01:00<00:57, 164.69it/s]\u001b[A\n",
      " 51%|█████▏    | 10050/19579 [01:01<00:57, 164.71it/s]\u001b[A\n",
      " 51%|█████▏    | 10069/19579 [01:01<00:57, 164.71it/s]\u001b[A\n",
      " 52%|█████▏    | 10090/19579 [01:01<00:57, 164.78it/s]\u001b[A\n",
      " 52%|█████▏    | 10110/19579 [01:01<00:57, 164.82it/s]\u001b[A\n",
      " 52%|█████▏    | 10129/19579 [01:01<00:57, 164.82it/s]\u001b[A\n",
      " 52%|█████▏    | 10147/19579 [01:01<00:57, 164.83it/s]\u001b[A\n",
      " 52%|█████▏    | 10165/19579 [01:01<00:57, 164.84it/s]\u001b[A\n",
      " 52%|█████▏    | 10183/19579 [01:01<00:56, 164.87it/s]\u001b[A\n",
      " 52%|█████▏    | 10201/19579 [01:01<00:56, 164.84it/s]\u001b[A\n",
      " 52%|█████▏    | 10218/19579 [01:02<00:56, 164.79it/s]\u001b[A\n",
      " 52%|█████▏    | 10237/19579 [01:02<00:56, 164.82it/s]\u001b[A\n",
      " 52%|█████▏    | 10254/19579 [01:02<00:56, 164.80it/s]\u001b[A\n",
      " 52%|█████▏    | 10271/19579 [01:02<00:56, 164.72it/s]\u001b[A\n",
      " 53%|█████▎    | 10290/19579 [01:02<00:56, 164.75it/s]\u001b[A\n",
      " 53%|█████▎    | 10308/19579 [01:02<00:56, 164.76it/s]\u001b[A\n",
      " 53%|█████▎    | 10325/19579 [01:02<00:56, 164.74it/s]\u001b[A\n",
      " 53%|█████▎    | 10342/19579 [01:02<00:56, 164.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 10359/19579 [01:02<00:55, 164.67it/s]\u001b[A\n",
      " 53%|█████▎    | 10376/19579 [01:03<00:55, 164.67it/s]\u001b[A\n",
      " 53%|█████▎    | 10392/19579 [01:03<00:55, 164.65it/s]\u001b[A\n",
      " 53%|█████▎    | 10410/19579 [01:03<00:55, 164.66it/s]\u001b[A\n",
      " 53%|█████▎    | 10429/19579 [01:03<00:55, 164.68it/s]\u001b[A\n",
      " 53%|█████▎    | 10446/19579 [01:03<00:55, 164.68it/s]\u001b[A\n",
      " 53%|█████▎    | 10467/19579 [01:03<00:55, 164.73it/s]\u001b[A\n",
      " 54%|█████▎    | 10485/19579 [01:03<00:55, 164.69it/s]\u001b[A\n",
      " 54%|█████▎    | 10506/19579 [01:03<00:55, 164.75it/s]\u001b[A\n",
      " 54%|█████▍    | 10529/19579 [01:03<00:54, 164.84it/s]\u001b[A\n",
      " 54%|█████▍    | 10549/19579 [01:03<00:54, 164.88it/s]\u001b[A\n",
      " 54%|█████▍    | 10569/19579 [01:04<00:54, 164.93it/s]\u001b[A\n",
      " 54%|█████▍    | 10589/19579 [01:04<00:54, 164.98it/s]\u001b[A\n",
      " 54%|█████▍    | 10609/19579 [01:04<00:54, 164.98it/s]\u001b[A\n",
      " 54%|█████▍    | 10628/19579 [01:04<00:54, 164.98it/s]\u001b[A\n",
      " 54%|█████▍    | 10646/19579 [01:04<00:54, 164.94it/s]\u001b[A\n",
      " 54%|█████▍    | 10663/19579 [01:04<00:54, 164.89it/s]\u001b[A\n",
      " 55%|█████▍    | 10679/19579 [01:04<00:53, 164.88it/s]\u001b[A\n",
      " 55%|█████▍    | 10697/19579 [01:04<00:53, 164.89it/s]\u001b[A\n",
      " 55%|█████▍    | 10717/19579 [01:04<00:53, 164.91it/s]\u001b[A\n",
      " 55%|█████▍    | 10737/19579 [01:05<00:53, 164.95it/s]\u001b[A\n",
      " 55%|█████▍    | 10755/19579 [01:05<00:53, 164.94it/s]\u001b[A\n",
      " 55%|█████▌    | 10775/19579 [01:05<00:53, 164.99it/s]\u001b[A\n",
      " 55%|█████▌    | 10797/19579 [01:05<00:53, 165.07it/s]\u001b[A\n",
      " 55%|█████▌    | 10817/19579 [01:05<00:53, 165.08it/s]\u001b[A\n",
      " 55%|█████▌    | 10836/19579 [01:05<00:52, 165.04it/s]\u001b[A\n",
      " 55%|█████▌    | 10855/19579 [01:05<00:52, 165.07it/s]\u001b[A\n",
      " 56%|█████▌    | 10875/19579 [01:05<00:52, 165.12it/s]\u001b[A\n",
      " 56%|█████▌    | 10894/19579 [01:05<00:52, 165.08it/s]\u001b[A\n",
      " 56%|█████▌    | 10912/19579 [01:06<00:52, 165.08it/s]\u001b[A\n",
      " 56%|█████▌    | 10929/19579 [01:06<00:52, 165.06it/s]\u001b[A\n",
      " 56%|█████▌    | 10946/19579 [01:06<00:52, 164.92it/s]\u001b[A\n",
      " 56%|█████▌    | 10967/19579 [01:06<00:52, 164.98it/s]\u001b[A\n",
      " 56%|█████▌    | 10984/19579 [01:06<00:52, 164.98it/s]\u001b[A\n",
      " 56%|█████▌    | 11002/19579 [01:06<00:51, 164.97it/s]\u001b[A\n",
      " 56%|█████▋    | 11019/19579 [01:06<00:51, 164.97it/s]\u001b[A\n",
      " 56%|█████▋    | 11036/19579 [01:06<00:51, 164.94it/s]\u001b[A\n",
      " 56%|█████▋    | 11055/19579 [01:07<00:51, 164.96it/s]\u001b[A\n",
      " 57%|█████▋    | 11076/19579 [01:07<00:51, 165.02it/s]\u001b[A\n",
      " 57%|█████▋    | 11094/19579 [01:07<00:51, 165.04it/s]\u001b[A\n",
      " 57%|█████▋    | 11112/19579 [01:07<00:51, 165.01it/s]\u001b[A\n",
      " 57%|█████▋    | 11130/19579 [01:07<00:51, 165.03it/s]\u001b[A\n",
      " 57%|█████▋    | 11149/19579 [01:07<00:51, 165.05it/s]\u001b[A\n",
      " 57%|█████▋    | 11167/19579 [01:07<00:50, 165.05it/s]\u001b[A\n",
      " 57%|█████▋    | 11187/19579 [01:07<00:50, 165.09it/s]\u001b[A\n",
      " 57%|█████▋    | 11206/19579 [01:07<00:50, 165.13it/s]\u001b[A\n",
      " 57%|█████▋    | 11225/19579 [01:07<00:50, 165.14it/s]\u001b[A\n",
      " 57%|█████▋    | 11243/19579 [01:08<00:50, 165.11it/s]\u001b[A\n",
      " 58%|█████▊    | 11262/19579 [01:08<00:50, 165.14it/s]\u001b[A\n",
      " 58%|█████▊    | 11280/19579 [01:08<00:50, 165.14it/s]\u001b[A\n",
      " 58%|█████▊    | 11299/19579 [01:08<00:50, 165.17it/s]\u001b[A\n",
      " 58%|█████▊    | 11317/19579 [01:08<00:50, 165.17it/s]\u001b[A\n",
      " 58%|█████▊    | 11338/19579 [01:08<00:49, 165.23it/s]\u001b[A\n",
      " 58%|█████▊    | 11359/19579 [01:08<00:49, 165.29it/s]\u001b[A\n",
      " 58%|█████▊    | 11378/19579 [01:08<00:49, 165.30it/s]\u001b[A\n",
      " 58%|█████▊    | 11397/19579 [01:08<00:49, 165.32it/s]\u001b[A\n",
      " 58%|█████▊    | 11416/19579 [01:09<00:49, 165.35it/s]\u001b[A\n",
      " 58%|█████▊    | 11435/19579 [01:09<00:49, 165.37it/s]\u001b[A\n",
      " 59%|█████▊    | 11454/19579 [01:09<00:49, 165.37it/s]\u001b[A\n",
      " 59%|█████▊    | 11474/19579 [01:09<00:48, 165.41it/s]\u001b[A\n",
      " 59%|█████▊    | 11495/19579 [01:09<00:48, 165.47it/s]\u001b[A\n",
      " 59%|█████▉    | 11515/19579 [01:09<00:48, 165.51it/s]\u001b[A\n",
      " 59%|█████▉    | 11535/19579 [01:09<00:48, 165.45it/s]\u001b[A\n",
      " 59%|█████▉    | 11555/19579 [01:09<00:48, 165.50it/s]\u001b[A\n",
      " 59%|█████▉    | 11575/19579 [01:09<00:48, 165.54it/s]\u001b[A\n",
      " 59%|█████▉    | 11594/19579 [01:10<00:48, 165.54it/s]\u001b[A\n",
      " 59%|█████▉    | 11612/19579 [01:10<00:48, 165.55it/s]\u001b[A\n",
      " 59%|█████▉    | 11630/19579 [01:10<00:48, 165.56it/s]\u001b[A\n",
      " 60%|█████▉    | 11652/19579 [01:10<00:47, 165.62it/s]\u001b[A\n",
      " 60%|█████▉    | 11675/19579 [01:10<00:47, 165.71it/s]\u001b[A\n",
      " 60%|█████▉    | 11695/19579 [01:10<00:47, 165.72it/s]\u001b[A\n",
      " 60%|█████▉    | 11714/19579 [01:10<00:47, 165.73it/s]\u001b[A\n",
      " 60%|█████▉    | 11733/19579 [01:10<00:47, 165.75it/s]\u001b[A\n",
      " 60%|██████    | 11752/19579 [01:10<00:47, 165.72it/s]\u001b[A\n",
      " 60%|██████    | 11770/19579 [01:11<00:47, 165.70it/s]\u001b[A\n",
      " 60%|██████    | 11792/19579 [01:11<00:46, 165.78it/s]\u001b[A\n",
      " 60%|██████    | 11812/19579 [01:11<00:46, 165.81it/s]\u001b[A\n",
      " 60%|██████    | 11831/19579 [01:11<00:46, 165.83it/s]\u001b[A\n",
      " 61%|██████    | 11852/19579 [01:11<00:46, 165.88it/s]\u001b[A\n",
      " 61%|██████    | 11871/19579 [01:11<00:46, 165.88it/s]\u001b[A\n",
      " 61%|██████    | 11890/19579 [01:11<00:46, 165.90it/s]\u001b[A\n",
      " 61%|██████    | 11909/19579 [01:11<00:46, 165.92it/s]\u001b[A\n",
      " 61%|██████    | 11928/19579 [01:11<00:46, 165.87it/s]\u001b[A\n",
      " 61%|██████    | 11945/19579 [01:12<00:46, 165.83it/s]\u001b[A\n",
      " 61%|██████    | 11964/19579 [01:12<00:45, 165.85it/s]\u001b[A\n",
      " 61%|██████    | 11982/19579 [01:12<00:45, 165.87it/s]\u001b[A\n",
      " 61%|██████▏   | 12001/19579 [01:12<00:45, 165.90it/s]\u001b[A\n",
      " 61%|██████▏   | 12019/19579 [01:12<00:45, 165.86it/s]\u001b[A\n",
      " 61%|██████▏   | 12037/19579 [01:12<00:45, 165.87it/s]\u001b[A\n",
      " 62%|██████▏   | 12057/19579 [01:12<00:45, 165.91it/s]\u001b[A\n",
      " 62%|██████▏   | 12075/19579 [01:12<00:45, 165.90it/s]\u001b[A\n",
      " 62%|██████▏   | 12093/19579 [01:12<00:45, 165.91it/s]\u001b[A\n",
      " 62%|██████▏   | 12111/19579 [01:12<00:45, 165.92it/s]\u001b[A\n",
      " 62%|██████▏   | 12129/19579 [01:13<00:44, 165.92it/s]\u001b[A\n",
      " 62%|██████▏   | 12152/19579 [01:13<00:44, 166.00it/s]\u001b[A\n",
      " 62%|██████▏   | 12171/19579 [01:13<00:44, 166.01it/s]\u001b[A\n",
      " 62%|██████▏   | 12190/19579 [01:13<00:44, 166.04it/s]\u001b[A\n",
      " 62%|██████▏   | 12209/19579 [01:13<00:44, 166.07it/s]\u001b[A\n",
      " 62%|██████▏   | 12228/19579 [01:13<00:44, 166.03it/s]\u001b[A\n",
      " 63%|██████▎   | 12246/19579 [01:13<00:44, 166.04it/s]\u001b[A\n",
      " 63%|██████▎   | 12267/19579 [01:13<00:44, 166.10it/s]\u001b[A\n",
      " 63%|██████▎   | 12286/19579 [01:13<00:43, 166.04it/s]\u001b[A\n",
      " 63%|██████▎   | 12303/19579 [01:14<00:43, 165.95it/s]\u001b[A\n",
      " 63%|██████▎   | 12327/19579 [01:14<00:43, 166.05it/s]\u001b[A\n",
      " 63%|██████▎   | 12348/19579 [01:14<00:43, 166.10it/s]\u001b[A\n",
      " 63%|██████▎   | 12369/19579 [01:14<00:43, 166.16it/s]\u001b[A\n",
      " 63%|██████▎   | 12389/19579 [01:14<00:43, 166.13it/s]\u001b[A\n",
      " 63%|██████▎   | 12408/19579 [01:14<00:43, 166.15it/s]\u001b[A\n",
      " 63%|██████▎   | 12426/19579 [01:14<00:43, 166.05it/s]\u001b[A\n",
      " 64%|██████▎   | 12444/19579 [01:14<00:42, 166.07it/s]\u001b[A\n",
      " 64%|██████▎   | 12461/19579 [01:15<00:42, 166.05it/s]\u001b[A\n",
      " 64%|██████▎   | 12481/19579 [01:15<00:42, 166.09it/s]\u001b[A\n",
      " 64%|██████▍   | 12499/19579 [01:15<00:42, 166.10it/s]\u001b[A\n",
      " 64%|██████▍   | 12517/19579 [01:15<00:42, 166.09it/s]\u001b[A\n",
      " 64%|██████▍   | 12534/19579 [01:15<00:42, 166.09it/s]\u001b[A\n",
      " 64%|██████▍   | 12552/19579 [01:15<00:42, 166.10it/s]\u001b[A\n",
      " 64%|██████▍   | 12570/19579 [01:15<00:42, 166.11it/s]\u001b[A\n",
      " 64%|██████▍   | 12588/19579 [01:15<00:42, 166.12it/s]\u001b[A\n",
      " 64%|██████▍   | 12606/19579 [01:15<00:41, 166.10it/s]\u001b[A\n",
      " 64%|██████▍   | 12627/19579 [01:15<00:41, 166.15it/s]\u001b[A\n",
      " 65%|██████▍   | 12645/19579 [01:16<00:41, 166.15it/s]\u001b[A\n",
      " 65%|██████▍   | 12666/19579 [01:16<00:41, 166.19it/s]\u001b[A\n",
      " 65%|██████▍   | 12686/19579 [01:16<00:41, 166.23it/s]\u001b[A\n",
      " 65%|██████▍   | 12705/19579 [01:16<00:41, 166.21it/s]\u001b[A\n",
      " 65%|██████▍   | 12723/19579 [01:16<00:41, 166.20it/s]\u001b[A\n",
      " 65%|██████▌   | 12743/19579 [01:16<00:41, 166.24it/s]\u001b[A\n",
      " 65%|██████▌   | 12761/19579 [01:16<00:41, 166.22it/s]\u001b[A\n",
      " 65%|██████▌   | 12779/19579 [01:16<00:40, 166.21it/s]\u001b[A\n",
      " 65%|██████▌   | 12798/19579 [01:16<00:40, 166.24it/s]\u001b[A\n",
      " 65%|██████▌   | 12817/19579 [01:17<00:40, 166.27it/s]\u001b[A\n",
      " 66%|██████▌   | 12838/19579 [01:17<00:40, 166.32it/s]\u001b[A\n",
      " 66%|██████▌   | 12857/19579 [01:17<00:40, 166.35it/s]\u001b[A\n",
      " 66%|██████▌   | 12876/19579 [01:17<00:40, 166.37it/s]\u001b[A\n",
      " 66%|██████▌   | 12895/19579 [01:17<00:40, 166.36it/s]\u001b[A\n",
      " 66%|██████▌   | 12915/19579 [01:17<00:40, 166.40it/s]\u001b[A\n",
      " 66%|██████▌   | 12934/19579 [01:17<00:39, 166.39it/s]\u001b[A\n",
      " 66%|██████▌   | 12952/19579 [01:17<00:39, 166.41it/s]\u001b[A\n",
      " 66%|██████▌   | 12970/19579 [01:17<00:39, 166.40it/s]\u001b[A\n",
      " 66%|██████▋   | 12989/19579 [01:18<00:39, 166.41it/s]\u001b[A\n",
      " 66%|██████▋   | 13007/19579 [01:18<00:39, 166.40it/s]\u001b[A\n",
      " 67%|██████▋   | 13024/19579 [01:18<00:39, 166.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 13041/19579 [01:18<00:39, 166.40it/s]\u001b[A\n",
      " 67%|██████▋   | 13058/19579 [01:18<00:39, 166.37it/s]\u001b[A\n",
      " 67%|██████▋   | 13076/19579 [01:18<00:39, 166.38it/s]\u001b[A\n",
      " 67%|██████▋   | 13093/19579 [01:18<00:38, 166.36it/s]\u001b[A\n",
      " 67%|██████▋   | 13114/19579 [01:18<00:38, 166.40it/s]\u001b[A\n",
      " 67%|██████▋   | 13132/19579 [01:18<00:38, 166.38it/s]\u001b[A\n",
      " 67%|██████▋   | 13149/19579 [01:19<00:38, 166.34it/s]\u001b[A\n",
      " 67%|██████▋   | 13165/19579 [01:19<00:38, 166.32it/s]\u001b[A\n",
      " 67%|██████▋   | 13181/19579 [01:19<00:38, 166.29it/s]\u001b[A\n",
      " 67%|██████▋   | 13199/19579 [01:19<00:38, 166.31it/s]\u001b[A\n",
      " 68%|██████▊   | 13218/19579 [01:19<00:38, 166.33it/s]\u001b[A\n",
      " 68%|██████▊   | 13236/19579 [01:19<00:38, 166.34it/s]\u001b[A\n",
      " 68%|██████▊   | 13254/19579 [01:19<00:38, 166.31it/s]\u001b[A\n",
      " 68%|██████▊   | 13278/19579 [01:19<00:37, 166.40it/s]\u001b[A\n",
      " 68%|██████▊   | 13297/19579 [01:19<00:37, 166.41it/s]\u001b[A\n",
      " 68%|██████▊   | 13316/19579 [01:20<00:37, 166.41it/s]\u001b[A\n",
      " 68%|██████▊   | 13337/19579 [01:20<00:37, 166.45it/s]\u001b[A\n",
      " 68%|██████▊   | 13356/19579 [01:20<00:37, 166.47it/s]\u001b[A\n",
      " 68%|██████▊   | 13375/19579 [01:20<00:37, 166.44it/s]\u001b[A\n",
      " 68%|██████▊   | 13393/19579 [01:20<00:37, 166.43it/s]\u001b[A\n",
      " 69%|██████▊   | 13415/19579 [01:20<00:37, 166.49it/s]\u001b[A\n",
      " 69%|██████▊   | 13434/19579 [01:20<00:36, 166.48it/s]\u001b[A\n",
      " 69%|██████▊   | 13453/19579 [01:20<00:36, 166.50it/s]\u001b[A\n",
      " 69%|██████▉   | 13472/19579 [01:20<00:36, 166.52it/s]\u001b[A\n",
      " 69%|██████▉   | 13490/19579 [01:21<00:36, 166.51it/s]\u001b[A\n",
      " 69%|██████▉   | 13508/19579 [01:21<00:36, 166.51it/s]\u001b[A\n",
      " 69%|██████▉   | 13530/19579 [01:21<00:36, 166.58it/s]\u001b[A\n",
      " 69%|██████▉   | 13549/19579 [01:21<00:36, 166.57it/s]\u001b[A\n",
      " 69%|██████▉   | 13567/19579 [01:21<00:36, 166.57it/s]\u001b[A\n",
      " 69%|██████▉   | 13585/19579 [01:21<00:35, 166.56it/s]\u001b[A\n",
      " 69%|██████▉   | 13603/19579 [01:21<00:35, 166.56it/s]\u001b[A\n",
      " 70%|██████▉   | 13621/19579 [01:21<00:35, 166.55it/s]\u001b[A\n",
      " 70%|██████▉   | 13640/19579 [01:21<00:35, 166.58it/s]\u001b[A\n",
      " 70%|██████▉   | 13664/19579 [01:21<00:35, 166.66it/s]\u001b[A\n",
      " 70%|██████▉   | 13687/19579 [01:22<00:35, 166.73it/s]\u001b[A\n",
      " 70%|███████   | 13708/19579 [01:22<00:35, 166.73it/s]\u001b[A\n",
      " 70%|███████   | 13728/19579 [01:22<00:35, 166.73it/s]\u001b[A\n",
      " 70%|███████   | 13747/19579 [01:22<00:34, 166.69it/s]\u001b[A\n",
      " 70%|███████   | 13765/19579 [01:22<00:34, 166.69it/s]\u001b[A\n",
      " 70%|███████   | 13782/19579 [01:22<00:34, 166.69it/s]\u001b[A\n",
      " 70%|███████   | 13799/19579 [01:22<00:34, 166.68it/s]\u001b[A\n",
      " 71%|███████   | 13823/19579 [01:22<00:34, 166.75it/s]\u001b[A\n",
      " 71%|███████   | 13842/19579 [01:22<00:34, 166.78it/s]\u001b[A\n",
      " 71%|███████   | 13862/19579 [01:23<00:34, 166.81it/s]\u001b[A\n",
      " 71%|███████   | 13882/19579 [01:23<00:34, 166.85it/s]\u001b[A\n",
      " 71%|███████   | 13902/19579 [01:23<00:34, 166.83it/s]\u001b[A\n",
      " 71%|███████   | 13920/19579 [01:23<00:33, 166.82it/s]\u001b[A\n",
      " 71%|███████   | 13939/19579 [01:23<00:33, 166.84it/s]\u001b[A\n",
      " 71%|███████▏  | 13957/19579 [01:23<00:33, 166.81it/s]\u001b[A\n",
      " 71%|███████▏  | 13978/19579 [01:23<00:33, 166.86it/s]\u001b[A\n",
      " 71%|███████▏  | 13996/19579 [01:23<00:33, 166.86it/s]\u001b[A\n",
      " 72%|███████▏  | 14014/19579 [01:23<00:33, 166.85it/s]\u001b[A\n",
      " 72%|███████▏  | 14032/19579 [01:24<00:33, 166.84it/s]\u001b[A\n",
      " 72%|███████▏  | 14049/19579 [01:24<00:33, 166.82it/s]\u001b[A\n",
      " 72%|███████▏  | 14066/19579 [01:24<00:33, 166.75it/s]\u001b[A\n",
      " 72%|███████▏  | 14082/19579 [01:24<00:32, 166.68it/s]\u001b[A\n",
      " 72%|███████▏  | 14102/19579 [01:24<00:32, 166.72it/s]\u001b[A\n",
      " 72%|███████▏  | 14119/19579 [01:24<00:32, 166.72it/s]\u001b[A\n",
      " 72%|███████▏  | 14136/19579 [01:24<00:32, 166.69it/s]\u001b[A\n",
      " 72%|███████▏  | 14152/19579 [01:24<00:32, 166.68it/s]\u001b[A\n",
      " 72%|███████▏  | 14170/19579 [01:25<00:32, 166.68it/s]\u001b[A\n",
      " 72%|███████▏  | 14187/19579 [01:25<00:32, 166.67it/s]\u001b[A\n",
      " 73%|███████▎  | 14204/19579 [01:25<00:32, 166.63it/s]\u001b[A\n",
      " 73%|███████▎  | 14222/19579 [01:25<00:32, 166.65it/s]\u001b[A\n",
      " 73%|███████▎  | 14239/19579 [01:25<00:32, 166.63it/s]\u001b[A\n",
      " 73%|███████▎  | 14257/19579 [01:25<00:31, 166.64it/s]\u001b[A\n",
      " 73%|███████▎  | 14274/19579 [01:25<00:31, 166.64it/s]\u001b[A\n",
      " 73%|███████▎  | 14291/19579 [01:25<00:31, 166.63it/s]\u001b[A\n",
      " 73%|███████▎  | 14308/19579 [01:25<00:31, 166.61it/s]\u001b[A\n",
      " 73%|███████▎  | 14325/19579 [01:25<00:31, 166.61it/s]\u001b[A\n",
      " 73%|███████▎  | 14342/19579 [01:26<00:31, 166.61it/s]\u001b[A\n",
      " 73%|███████▎  | 14359/19579 [01:26<00:31, 166.60it/s]\u001b[A\n",
      " 73%|███████▎  | 14377/19579 [01:26<00:31, 166.61it/s]\u001b[A\n",
      " 74%|███████▎  | 14394/19579 [01:26<00:31, 166.57it/s]\u001b[A\n",
      " 74%|███████▎  | 14411/19579 [01:26<00:31, 166.58it/s]\u001b[A\n",
      " 74%|███████▎  | 14428/19579 [01:26<00:30, 166.56it/s]\u001b[A\n",
      " 74%|███████▍  | 14446/19579 [01:26<00:30, 166.58it/s]\u001b[A\n",
      " 74%|███████▍  | 14463/19579 [01:26<00:30, 166.58it/s]\u001b[A\n",
      " 74%|███████▍  | 14482/19579 [01:26<00:30, 166.60it/s]\u001b[A\n",
      " 74%|███████▍  | 14504/19579 [01:27<00:30, 166.64it/s]\u001b[A\n",
      " 74%|███████▍  | 14525/19579 [01:27<00:30, 166.68it/s]\u001b[A\n",
      " 74%|███████▍  | 14544/19579 [01:27<00:30, 166.66it/s]\u001b[A\n",
      " 74%|███████▍  | 14562/19579 [01:27<00:30, 166.63it/s]\u001b[A\n",
      " 74%|███████▍  | 14580/19579 [01:27<00:29, 166.64it/s]\u001b[A\n",
      " 75%|███████▍  | 14597/19579 [01:27<00:29, 166.63it/s]\u001b[A\n",
      " 75%|███████▍  | 14615/19579 [01:27<00:29, 166.64it/s]\u001b[A\n",
      " 75%|███████▍  | 14632/19579 [01:27<00:29, 166.64it/s]\u001b[A\n",
      " 75%|███████▍  | 14649/19579 [01:27<00:29, 166.64it/s]\u001b[A\n",
      " 75%|███████▍  | 14666/19579 [01:28<00:29, 166.60it/s]\u001b[A\n",
      " 75%|███████▍  | 14682/19579 [01:28<00:29, 166.59it/s]\u001b[A\n",
      " 75%|███████▌  | 14698/19579 [01:28<00:29, 166.56it/s]\u001b[A\n",
      " 75%|███████▌  | 14714/19579 [01:28<00:29, 166.52it/s]\u001b[A\n",
      " 75%|███████▌  | 14733/19579 [01:28<00:29, 166.53it/s]\u001b[A\n",
      " 75%|███████▌  | 14754/19579 [01:28<00:28, 166.58it/s]\u001b[A\n",
      " 75%|███████▌  | 14772/19579 [01:28<00:28, 166.56it/s]\u001b[A\n",
      " 76%|███████▌  | 14789/19579 [01:28<00:28, 166.55it/s]\u001b[A\n",
      " 76%|███████▌  | 14807/19579 [01:28<00:28, 166.55it/s]\u001b[A\n",
      " 76%|███████▌  | 14825/19579 [01:29<00:28, 166.56it/s]\u001b[A\n",
      " 76%|███████▌  | 14842/19579 [01:29<00:28, 166.54it/s]\u001b[A\n",
      " 76%|███████▌  | 14859/19579 [01:29<00:28, 166.55it/s]\u001b[A\n",
      " 76%|███████▌  | 14876/19579 [01:29<00:28, 166.53it/s]\u001b[A\n",
      " 76%|███████▌  | 14898/19579 [01:29<00:28, 166.58it/s]\u001b[A\n",
      " 76%|███████▌  | 14916/19579 [01:29<00:27, 166.55it/s]\u001b[A\n",
      " 76%|███████▋  | 14933/19579 [01:29<00:27, 166.54it/s]\u001b[A\n",
      " 76%|███████▋  | 14950/19579 [01:29<00:27, 166.54it/s]\u001b[A\n",
      " 76%|███████▋  | 14968/19579 [01:29<00:27, 166.55it/s]\u001b[A\n",
      " 77%|███████▋  | 14989/19579 [01:29<00:27, 166.59it/s]\u001b[A\n",
      " 77%|███████▋  | 15007/19579 [01:30<00:27, 166.57it/s]\u001b[A\n",
      " 77%|███████▋  | 15025/19579 [01:30<00:27, 166.59it/s]\u001b[A\n",
      " 77%|███████▋  | 15043/19579 [01:30<00:27, 166.59it/s]\u001b[A\n",
      " 77%|███████▋  | 15061/19579 [01:30<00:27, 166.57it/s]\u001b[A\n",
      " 77%|███████▋  | 15078/19579 [01:30<00:27, 166.56it/s]\u001b[A\n",
      " 77%|███████▋  | 15095/19579 [01:30<00:26, 166.52it/s]\u001b[A\n",
      " 77%|███████▋  | 15112/19579 [01:30<00:26, 166.52it/s]\u001b[A\n",
      " 77%|███████▋  | 15129/19579 [01:30<00:26, 166.50it/s]\u001b[A\n",
      " 77%|███████▋  | 15148/19579 [01:30<00:26, 166.52it/s]\u001b[A\n",
      " 77%|███████▋  | 15165/19579 [01:31<00:26, 166.51it/s]\u001b[A\n",
      " 78%|███████▊  | 15182/19579 [01:31<00:26, 166.44it/s]\u001b[A\n",
      " 78%|███████▊  | 15200/19579 [01:31<00:26, 166.45it/s]\u001b[A\n",
      " 78%|███████▊  | 15216/19579 [01:31<00:26, 166.42it/s]\u001b[A\n",
      " 78%|███████▊  | 15234/19579 [01:31<00:26, 166.41it/s]\u001b[A\n",
      " 78%|███████▊  | 15251/19579 [01:31<00:26, 166.41it/s]\u001b[A\n",
      " 78%|███████▊  | 15270/19579 [01:31<00:25, 166.43it/s]\u001b[A\n",
      " 78%|███████▊  | 15287/19579 [01:31<00:25, 166.43it/s]\u001b[A\n",
      " 78%|███████▊  | 15304/19579 [01:31<00:25, 166.41it/s]\u001b[A\n",
      " 78%|███████▊  | 15323/19579 [01:32<00:25, 166.44it/s]\u001b[A\n",
      " 78%|███████▊  | 15341/19579 [01:32<00:25, 166.45it/s]\u001b[A\n",
      " 78%|███████▊  | 15359/19579 [01:32<00:25, 166.46it/s]\u001b[A\n",
      " 79%|███████▊  | 15377/19579 [01:32<00:25, 166.45it/s]\u001b[A\n",
      " 79%|███████▊  | 15394/19579 [01:32<00:25, 166.44it/s]\u001b[A\n",
      " 79%|███████▊  | 15412/19579 [01:32<00:25, 166.44it/s]\u001b[A\n",
      " 79%|███████▉  | 15429/19579 [01:32<00:24, 166.44it/s]\u001b[A\n",
      " 79%|███████▉  | 15446/19579 [01:32<00:24, 166.41it/s]\u001b[A\n",
      " 79%|███████▉  | 15463/19579 [01:32<00:24, 166.40it/s]\u001b[A\n",
      " 79%|███████▉  | 15480/19579 [01:33<00:24, 166.40it/s]\u001b[A\n",
      " 79%|███████▉  | 15497/19579 [01:33<00:24, 166.39it/s]\u001b[A\n",
      " 79%|███████▉  | 15516/19579 [01:33<00:24, 166.41it/s]\u001b[A\n",
      " 79%|███████▉  | 15538/19579 [01:33<00:24, 166.47it/s]\u001b[A\n",
      " 79%|███████▉  | 15557/19579 [01:33<00:24, 166.48it/s]\u001b[A\n",
      " 80%|███████▉  | 15581/19579 [01:33<00:24, 166.55it/s]\u001b[A\n",
      " 80%|███████▉  | 15601/19579 [01:33<00:23, 166.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 15620/19579 [01:33<00:23, 166.53it/s]\u001b[A\n",
      " 80%|███████▉  | 15639/19579 [01:33<00:23, 166.56it/s]\u001b[A\n",
      " 80%|███████▉  | 15658/19579 [01:34<00:23, 166.56it/s]\u001b[A\n",
      " 80%|████████  | 15676/19579 [01:34<00:23, 166.56it/s]\u001b[A\n",
      " 80%|████████  | 15694/19579 [01:34<00:23, 166.54it/s]\u001b[A\n",
      " 80%|████████  | 15711/19579 [01:34<00:23, 166.51it/s]\u001b[A\n",
      " 80%|████████  | 15728/19579 [01:34<00:23, 166.51it/s]\u001b[A\n",
      " 80%|████████  | 15745/19579 [01:34<00:23, 166.49it/s]\u001b[A\n",
      " 81%|████████  | 15762/19579 [01:34<00:22, 166.49it/s]\u001b[A\n",
      " 81%|████████  | 15778/19579 [01:34<00:22, 166.46it/s]\u001b[A\n",
      " 81%|████████  | 15797/19579 [01:34<00:22, 166.48it/s]\u001b[A\n",
      " 81%|████████  | 15814/19579 [01:34<00:22, 166.47it/s]\u001b[A\n",
      " 81%|████████  | 15831/19579 [01:35<00:22, 166.47it/s]\u001b[A\n",
      " 81%|████████  | 15848/19579 [01:35<00:22, 166.47it/s]\u001b[A\n",
      " 81%|████████  | 15866/19579 [01:35<00:22, 166.48it/s]\u001b[A\n",
      " 81%|████████  | 15885/19579 [01:35<00:22, 166.50it/s]\u001b[A\n",
      " 81%|████████  | 15906/19579 [01:35<00:22, 166.53it/s]\u001b[A\n",
      " 81%|████████▏ | 15924/19579 [01:35<00:21, 166.53it/s]\u001b[A\n",
      " 81%|████████▏ | 15942/19579 [01:35<00:21, 166.54it/s]\u001b[A\n",
      " 82%|████████▏ | 15960/19579 [01:35<00:21, 166.53it/s]\u001b[A\n",
      " 82%|████████▏ | 15978/19579 [01:35<00:21, 166.51it/s]\u001b[A\n",
      " 82%|████████▏ | 15995/19579 [01:36<00:21, 166.50it/s]\u001b[A\n",
      " 82%|████████▏ | 16012/19579 [01:36<00:21, 166.45it/s]\u001b[A\n",
      " 82%|████████▏ | 16028/19579 [01:36<00:21, 166.43it/s]\u001b[A\n",
      " 82%|████████▏ | 16047/19579 [01:36<00:21, 166.45it/s]\u001b[A\n",
      " 82%|████████▏ | 16068/19579 [01:36<00:21, 166.49it/s]\u001b[A\n",
      " 82%|████████▏ | 16087/19579 [01:36<00:20, 166.51it/s]\u001b[A\n",
      " 82%|████████▏ | 16105/19579 [01:36<00:20, 166.51it/s]\u001b[A\n",
      " 82%|████████▏ | 16125/19579 [01:36<00:20, 166.54it/s]\u001b[A\n",
      " 82%|████████▏ | 16144/19579 [01:36<00:20, 166.55it/s]\u001b[A\n",
      " 83%|████████▎ | 16162/19579 [01:37<00:20, 166.55it/s]\u001b[A\n",
      " 83%|████████▎ | 16182/19579 [01:37<00:20, 166.59it/s]\u001b[A\n",
      " 83%|████████▎ | 16201/19579 [01:37<00:20, 166.59it/s]\u001b[A\n",
      " 83%|████████▎ | 16220/19579 [01:37<00:20, 166.60it/s]\u001b[A\n",
      " 83%|████████▎ | 16238/19579 [01:37<00:20, 166.61it/s]\u001b[A\n",
      " 83%|████████▎ | 16256/19579 [01:37<00:19, 166.57it/s]\u001b[A\n",
      " 83%|████████▎ | 16273/19579 [01:37<00:19, 166.55it/s]\u001b[A\n",
      " 83%|████████▎ | 16290/19579 [01:37<00:19, 166.55it/s]\u001b[A\n",
      " 83%|████████▎ | 16307/19579 [01:37<00:19, 166.48it/s]\u001b[A\n",
      " 83%|████████▎ | 16325/19579 [01:38<00:19, 166.49it/s]\u001b[A\n",
      " 83%|████████▎ | 16343/19579 [01:38<00:19, 166.49it/s]\u001b[A\n",
      " 84%|████████▎ | 16361/19579 [01:38<00:19, 166.50it/s]\u001b[A\n",
      " 84%|████████▎ | 16380/19579 [01:38<00:19, 166.52it/s]\u001b[A\n",
      " 84%|████████▍ | 16398/19579 [01:38<00:19, 166.49it/s]\u001b[A\n",
      " 84%|████████▍ | 16415/19579 [01:38<00:19, 166.47it/s]\u001b[A\n",
      " 84%|████████▍ | 16432/19579 [01:38<00:18, 166.47it/s]\u001b[A\n",
      " 84%|████████▍ | 16450/19579 [01:38<00:18, 166.48it/s]\u001b[A\n",
      " 84%|████████▍ | 16467/19579 [01:38<00:18, 166.47it/s]\u001b[A\n",
      " 84%|████████▍ | 16484/19579 [01:39<00:18, 166.43it/s]\u001b[A\n",
      " 84%|████████▍ | 16506/19579 [01:39<00:18, 166.48it/s]\u001b[A\n",
      " 84%|████████▍ | 16524/19579 [01:39<00:18, 166.47it/s]\u001b[A\n",
      " 84%|████████▍ | 16541/19579 [01:39<00:18, 166.40it/s]\u001b[A\n",
      " 85%|████████▍ | 16557/19579 [01:39<00:18, 166.38it/s]\u001b[A\n",
      " 85%|████████▍ | 16576/19579 [01:39<00:18, 166.40it/s]\u001b[A\n",
      " 85%|████████▍ | 16594/19579 [01:39<00:17, 166.41it/s]\u001b[A\n",
      " 85%|████████▍ | 16612/19579 [01:39<00:17, 166.41it/s]\u001b[A\n",
      " 85%|████████▍ | 16629/19579 [01:39<00:17, 166.41it/s]\u001b[A\n",
      " 85%|████████▌ | 16646/19579 [01:40<00:17, 166.38it/s]\u001b[A\n",
      " 85%|████████▌ | 16666/19579 [01:40<00:17, 166.41it/s]\u001b[A\n",
      " 85%|████████▌ | 16684/19579 [01:40<00:17, 166.42it/s]\u001b[A\n",
      " 85%|████████▌ | 16702/19579 [01:40<00:17, 166.42it/s]\u001b[A\n",
      " 85%|████████▌ | 16723/19579 [01:40<00:17, 166.46it/s]\u001b[A\n",
      " 86%|████████▌ | 16742/19579 [01:40<00:17, 166.44it/s]\u001b[A\n",
      " 86%|████████▌ | 16760/19579 [01:40<00:16, 166.42it/s]\u001b[A\n",
      " 86%|████████▌ | 16777/19579 [01:40<00:16, 166.42it/s]\u001b[A\n",
      " 86%|████████▌ | 16794/19579 [01:40<00:16, 166.41it/s]\u001b[A\n",
      " 86%|████████▌ | 16811/19579 [01:41<00:16, 166.39it/s]\u001b[A\n",
      " 86%|████████▌ | 16830/19579 [01:41<00:16, 166.41it/s]\u001b[A\n",
      " 86%|████████▌ | 16848/19579 [01:41<00:16, 166.41it/s]\u001b[A\n",
      " 86%|████████▌ | 16866/19579 [01:41<00:16, 166.41it/s]\u001b[A\n",
      " 86%|████████▌ | 16886/19579 [01:41<00:16, 166.44it/s]\u001b[A\n",
      " 86%|████████▋ | 16904/19579 [01:41<00:16, 166.44it/s]\u001b[A\n",
      " 86%|████████▋ | 16922/19579 [01:41<00:15, 166.45it/s]\u001b[A\n",
      " 87%|████████▋ | 16942/19579 [01:41<00:15, 166.48it/s]\u001b[A\n",
      " 87%|████████▋ | 16964/19579 [01:41<00:15, 166.52it/s]\u001b[A\n",
      " 87%|████████▋ | 16983/19579 [01:41<00:15, 166.51it/s]\u001b[A\n",
      " 87%|████████▋ | 17001/19579 [01:42<00:15, 166.50it/s]\u001b[A\n",
      " 87%|████████▋ | 17019/19579 [01:42<00:15, 166.45it/s]\u001b[A\n",
      " 87%|████████▋ | 17039/19579 [01:42<00:15, 166.48it/s]\u001b[A\n",
      " 87%|████████▋ | 17060/19579 [01:42<00:15, 166.52it/s]\u001b[A\n",
      " 87%|████████▋ | 17079/19579 [01:42<00:15, 166.51it/s]\u001b[A\n",
      " 87%|████████▋ | 17097/19579 [01:42<00:14, 166.50it/s]\u001b[A\n",
      " 87%|████████▋ | 17115/19579 [01:42<00:14, 166.51it/s]\u001b[A\n",
      " 88%|████████▊ | 17134/19579 [01:42<00:14, 166.53it/s]\u001b[A\n",
      " 88%|████████▊ | 17153/19579 [01:42<00:14, 166.54it/s]\u001b[A\n",
      " 88%|████████▊ | 17174/19579 [01:43<00:14, 166.58it/s]\u001b[A\n",
      " 88%|████████▊ | 17193/19579 [01:43<00:14, 166.60it/s]\u001b[A\n",
      " 88%|████████▊ | 17212/19579 [01:43<00:14, 166.59it/s]\u001b[A\n",
      " 88%|████████▊ | 17230/19579 [01:43<00:14, 166.60it/s]\u001b[A\n",
      " 88%|████████▊ | 17250/19579 [01:43<00:13, 166.62it/s]\u001b[A\n",
      " 88%|████████▊ | 17269/19579 [01:43<00:13, 166.64it/s]\u001b[A\n",
      " 88%|████████▊ | 17288/19579 [01:43<00:13, 166.62it/s]\u001b[A\n",
      " 88%|████████▊ | 17306/19579 [01:43<00:13, 166.58it/s]\u001b[A\n",
      " 88%|████████▊ | 17325/19579 [01:43<00:13, 166.60it/s]\u001b[A\n",
      " 89%|████████▊ | 17346/19579 [01:44<00:13, 166.64it/s]\u001b[A\n",
      " 89%|████████▊ | 17364/19579 [01:44<00:13, 166.63it/s]\u001b[A\n",
      " 89%|████████▉ | 17382/19579 [01:44<00:13, 166.63it/s]\u001b[A\n",
      " 89%|████████▉ | 17400/19579 [01:44<00:13, 166.64it/s]\u001b[A\n",
      " 89%|████████▉ | 17418/19579 [01:44<00:12, 166.64it/s]\u001b[A\n",
      " 89%|████████▉ | 17436/19579 [01:44<00:12, 166.62it/s]\u001b[A\n",
      " 89%|████████▉ | 17453/19579 [01:44<00:12, 166.58it/s]\u001b[A\n",
      " 89%|████████▉ | 17471/19579 [01:44<00:12, 166.60it/s]\u001b[A\n",
      " 89%|████████▉ | 17490/19579 [01:44<00:12, 166.61it/s]\u001b[A\n",
      " 89%|████████▉ | 17508/19579 [01:45<00:12, 166.62it/s]\u001b[A\n",
      " 90%|████████▉ | 17526/19579 [01:45<00:12, 166.63it/s]\u001b[A\n",
      " 90%|████████▉ | 17544/19579 [01:45<00:12, 166.62it/s]\u001b[A\n",
      " 90%|████████▉ | 17561/19579 [01:45<00:12, 166.62it/s]\u001b[A\n",
      " 90%|████████▉ | 17578/19579 [01:45<00:12, 166.62it/s]\u001b[A\n",
      " 90%|████████▉ | 17595/19579 [01:45<00:11, 166.62it/s]\u001b[A\n",
      " 90%|████████▉ | 17612/19579 [01:45<00:11, 166.62it/s]\u001b[A\n",
      " 90%|█████████ | 17630/19579 [01:45<00:11, 166.62it/s]\u001b[A\n",
      " 90%|█████████ | 17647/19579 [01:45<00:11, 166.58it/s]\u001b[A\n",
      " 90%|█████████ | 17663/19579 [01:46<00:11, 166.55it/s]\u001b[A\n",
      " 90%|█████████ | 17680/19579 [01:46<00:11, 166.54it/s]\u001b[A\n",
      " 90%|█████████ | 17699/19579 [01:46<00:11, 166.56it/s]\u001b[A\n",
      " 91%|█████████ | 17719/19579 [01:46<00:11, 166.59it/s]\u001b[A\n",
      " 91%|█████████ | 17738/19579 [01:46<00:11, 166.61it/s]\u001b[A\n",
      " 91%|█████████ | 17760/19579 [01:46<00:10, 166.65it/s]\u001b[A\n",
      " 91%|█████████ | 17779/19579 [01:46<00:10, 166.67it/s]\u001b[A\n",
      " 91%|█████████ | 17801/19579 [01:46<00:10, 166.71it/s]\u001b[A\n",
      " 91%|█████████ | 17821/19579 [01:46<00:10, 166.72it/s]\u001b[A\n",
      " 91%|█████████ | 17843/19579 [01:46<00:10, 166.77it/s]\u001b[A\n",
      " 91%|█████████ | 17863/19579 [01:47<00:10, 166.75it/s]\u001b[A\n",
      " 91%|█████████▏| 17882/19579 [01:47<00:10, 166.74it/s]\u001b[A\n",
      " 91%|█████████▏| 17900/19579 [01:47<00:10, 166.75it/s]\u001b[A\n",
      " 92%|█████████▏| 17918/19579 [01:47<00:09, 166.74it/s]\u001b[A\n",
      " 92%|█████████▏| 17938/19579 [01:47<00:09, 166.77it/s]\u001b[A\n",
      " 92%|█████████▏| 17958/19579 [01:47<00:09, 166.80it/s]\u001b[A\n",
      " 92%|█████████▏| 17977/19579 [01:47<00:09, 166.82it/s]\u001b[A\n",
      " 92%|█████████▏| 17996/19579 [01:47<00:09, 166.83it/s]\u001b[A\n",
      " 92%|█████████▏| 18015/19579 [01:47<00:09, 166.82it/s]\u001b[A\n",
      " 92%|█████████▏| 18034/19579 [01:48<00:09, 166.84it/s]\u001b[A\n",
      " 92%|█████████▏| 18052/19579 [01:48<00:09, 166.81it/s]\u001b[A\n",
      " 92%|█████████▏| 18071/19579 [01:48<00:09, 166.83it/s]\u001b[A\n",
      " 92%|█████████▏| 18089/19579 [01:48<00:08, 166.82it/s]\u001b[A\n",
      " 92%|█████████▏| 18106/19579 [01:48<00:08, 166.82it/s]\u001b[A\n",
      " 93%|█████████▎| 18123/19579 [01:48<00:08, 166.68it/s]\u001b[A\n",
      " 93%|█████████▎| 18142/19579 [01:48<00:08, 166.69it/s]\u001b[A\n",
      " 93%|█████████▎| 18162/19579 [01:48<00:08, 166.72it/s]\u001b[A\n",
      " 93%|█████████▎| 18179/19579 [01:49<00:08, 166.71it/s]\u001b[A\n",
      " 93%|█████████▎| 18198/19579 [01:49<00:08, 166.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 18216/19579 [01:49<00:08, 166.70it/s]\u001b[A\n",
      " 93%|█████████▎| 18233/19579 [01:49<00:08, 166.68it/s]\u001b[A\n",
      " 93%|█████████▎| 18249/19579 [01:49<00:07, 166.66it/s]\u001b[A\n",
      " 93%|█████████▎| 18270/19579 [01:49<00:07, 166.70it/s]\u001b[A\n",
      " 93%|█████████▎| 18290/19579 [01:49<00:07, 166.72it/s]\u001b[A\n",
      " 94%|█████████▎| 18310/19579 [01:49<00:07, 166.75it/s]\u001b[A\n",
      " 94%|█████████▎| 18329/19579 [01:49<00:07, 166.77it/s]\u001b[A\n",
      " 94%|█████████▎| 18348/19579 [01:50<00:07, 166.78it/s]\u001b[A\n",
      " 94%|█████████▍| 18368/19579 [01:50<00:07, 166.81it/s]\u001b[A\n",
      " 94%|█████████▍| 18387/19579 [01:50<00:07, 166.80it/s]\u001b[A\n",
      " 94%|█████████▍| 18405/19579 [01:50<00:07, 166.78it/s]\u001b[A\n",
      " 94%|█████████▍| 18425/19579 [01:50<00:06, 166.81it/s]\u001b[A\n",
      " 94%|█████████▍| 18443/19579 [01:50<00:06, 166.82it/s]\u001b[A\n",
      " 94%|█████████▍| 18461/19579 [01:50<00:06, 166.78it/s]\u001b[A\n",
      " 94%|█████████▍| 18478/19579 [01:50<00:06, 166.76it/s]\u001b[A\n",
      " 94%|█████████▍| 18495/19579 [01:50<00:06, 166.75it/s]\u001b[A\n",
      " 95%|█████████▍| 18511/19579 [01:51<00:06, 166.71it/s]\u001b[A\n",
      " 95%|█████████▍| 18528/19579 [01:51<00:06, 166.71it/s]\u001b[A\n",
      " 95%|█████████▍| 18545/19579 [01:51<00:06, 166.70it/s]\u001b[A\n",
      " 95%|█████████▍| 18561/19579 [01:51<00:06, 166.67it/s]\u001b[A\n",
      " 95%|█████████▍| 18577/19579 [01:51<00:06, 166.65it/s]\u001b[A\n",
      " 95%|█████████▍| 18596/19579 [01:51<00:05, 166.66it/s]\u001b[A\n",
      " 95%|█████████▌| 18614/19579 [01:51<00:05, 166.67it/s]\u001b[A\n",
      " 95%|█████████▌| 18631/19579 [01:51<00:05, 166.64it/s]\u001b[A\n",
      " 95%|█████████▌| 18649/19579 [01:51<00:05, 166.65it/s]\u001b[A\n",
      " 95%|█████████▌| 18666/19579 [01:52<00:05, 166.64it/s]\u001b[A\n",
      " 95%|█████████▌| 18684/19579 [01:52<00:05, 166.65it/s]\u001b[A\n",
      " 96%|█████████▌| 18704/19579 [01:52<00:05, 166.67it/s]\u001b[A\n",
      " 96%|█████████▌| 18723/19579 [01:52<00:05, 166.69it/s]\u001b[A\n",
      " 96%|█████████▌| 18743/19579 [01:52<00:05, 166.71it/s]\u001b[A\n",
      " 96%|█████████▌| 18764/19579 [01:52<00:04, 166.75it/s]\u001b[A\n",
      " 96%|█████████▌| 18783/19579 [01:52<00:04, 166.74it/s]\u001b[A\n",
      " 96%|█████████▌| 18802/19579 [01:52<00:04, 166.75it/s]\u001b[A\n",
      " 96%|█████████▌| 18820/19579 [01:52<00:04, 166.75it/s]\u001b[A\n",
      " 96%|█████████▌| 18838/19579 [01:52<00:04, 166.76it/s]\u001b[A\n",
      " 96%|█████████▋| 18856/19579 [01:53<00:04, 166.75it/s]\u001b[A\n",
      " 96%|█████████▋| 18874/19579 [01:53<00:04, 166.76it/s]\u001b[A\n",
      " 97%|█████████▋| 18894/19579 [01:53<00:04, 166.78it/s]\u001b[A\n",
      " 97%|█████████▋| 18915/19579 [01:53<00:03, 166.82it/s]\u001b[A\n",
      " 97%|█████████▋| 18934/19579 [01:53<00:03, 166.83it/s]\u001b[A\n",
      " 97%|█████████▋| 18953/19579 [01:53<00:03, 166.84it/s]\u001b[A\n",
      " 97%|█████████▋| 18972/19579 [01:53<00:03, 166.84it/s]\u001b[A\n",
      " 97%|█████████▋| 18990/19579 [01:53<00:03, 166.83it/s]\u001b[A\n",
      " 97%|█████████▋| 19008/19579 [01:53<00:03, 166.83it/s]\u001b[A\n",
      " 97%|█████████▋| 19026/19579 [01:54<00:03, 166.82it/s]\u001b[A\n",
      " 97%|█████████▋| 19043/19579 [01:54<00:03, 166.82it/s]\u001b[A\n",
      " 97%|█████████▋| 19062/19579 [01:54<00:03, 166.84it/s]\u001b[A\n",
      " 97%|█████████▋| 19080/19579 [01:54<00:02, 166.85it/s]\u001b[A\n",
      " 98%|█████████▊| 19098/19579 [01:54<00:02, 166.83it/s]\u001b[A\n",
      " 98%|█████████▊| 19119/19579 [01:54<00:02, 166.86it/s]\u001b[A\n",
      " 98%|█████████▊| 19138/19579 [01:54<00:02, 166.88it/s]\u001b[A\n",
      " 98%|█████████▊| 19157/19579 [01:54<00:02, 166.89it/s]\u001b[A\n",
      " 98%|█████████▊| 19178/19579 [01:54<00:02, 166.93it/s]\u001b[A\n",
      " 98%|█████████▊| 19197/19579 [01:55<00:02, 166.89it/s]\u001b[A\n",
      " 98%|█████████▊| 19216/19579 [01:55<00:02, 166.91it/s]\u001b[A\n",
      " 98%|█████████▊| 19234/19579 [01:55<00:02, 166.91it/s]\u001b[A\n",
      " 98%|█████████▊| 19253/19579 [01:55<00:01, 166.93it/s]\u001b[A\n",
      " 98%|█████████▊| 19271/19579 [01:55<00:01, 166.87it/s]\u001b[A\n",
      " 99%|█████████▊| 19289/19579 [01:55<00:01, 166.88it/s]\u001b[A\n",
      " 99%|█████████▊| 19308/19579 [01:55<00:01, 166.89it/s]\u001b[A\n",
      " 99%|█████████▊| 19327/19579 [01:55<00:01, 166.91it/s]\u001b[A\n",
      " 99%|█████████▉| 19345/19579 [01:55<00:01, 166.91it/s]\u001b[A\n",
      " 99%|█████████▉| 19365/19579 [01:56<00:01, 166.93it/s]\u001b[A\n",
      " 99%|█████████▉| 19384/19579 [01:56<00:01, 166.95it/s]\u001b[A\n",
      " 99%|█████████▉| 19403/19579 [01:56<00:01, 166.96it/s]\u001b[A\n",
      " 99%|█████████▉| 19423/19579 [01:56<00:00, 166.98it/s]\u001b[A\n",
      " 99%|█████████▉| 19442/19579 [01:56<00:00, 166.98it/s]\u001b[A\n",
      " 99%|█████████▉| 19461/19579 [01:56<00:00, 167.00it/s]\u001b[A\n",
      " 99%|█████████▉| 19481/19579 [01:56<00:00, 167.02it/s]\u001b[A\n",
      "100%|█████████▉| 19500/19579 [01:56<00:00, 167.02it/s]\u001b[A\n",
      "100%|█████████▉| 19519/19579 [01:56<00:00, 167.02it/s]\u001b[A\n",
      "100%|█████████▉| 19537/19579 [01:56<00:00, 167.01it/s]\u001b[A\n",
      "100%|█████████▉| 19557/19579 [01:57<00:00, 167.03it/s]\u001b[A\n",
      "100%|█████████▉| 19575/19579 [01:57<00:00, 167.04it/s]\u001b[A\n",
      "100%|██████████| 8392/8392 [00:47<00:00, 176.21it/s]s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "def loadWordVecs():\n",
    "    embeddings_index = {}\n",
    "    f = open(wv)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "def sent2vec(embeddings_index,s): # this function creates a normalized vector for the whole sentence\n",
    "    words = str(s).lower().decode('utf-8')\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stopwords.words('english')]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(50)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "def doGlove(x_train,x_test):\n",
    "    embeddings_index = loadWordVecs()\n",
    "    # create sentence vectors using the above function for training and validation set\n",
    "    xtrain_glove = [sent2vec(embeddings_index,x) for x in tqdm(x_train)]\n",
    "    xtest_glove = [sent2vec(embeddings_index,x) for x in tqdm(x_test)]\n",
    "    xtrain_glove = np.array(xtrain_glove)\n",
    "    xtest_glove = np.array(xtest_glove)\n",
    "    return xtrain_glove,xtest_glove\n",
    "\n",
    "glove_vecs_train,glove_vecs_test = doGlove(X_train['text'],X_test['text'])\n",
    "X_train[['sent_vec_'+str(i) for i in range(50)]] = pd.DataFrame(glove_vecs_train.tolist())\n",
    "X_test[['sent_vec_'+str(i) for i in range(50)]] = pd.DataFrame(glove_vecs_test.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/10\n",
      "15663/15663 [==============================] - 8s 522us/step - loss: 1.1392 - val_loss: 0.9202\n",
      "Epoch 2/10\n",
      "15663/15663 [==============================] - 4s 264us/step - loss: 0.8715 - val_loss: 0.8555\n",
      "Epoch 3/10\n",
      "15663/15663 [==============================] - 4s 265us/step - loss: 0.8250 - val_loss: 0.8390\n",
      "Epoch 4/10\n",
      "15663/15663 [==============================] - 4s 262us/step - loss: 0.7949 - val_loss: 0.8507\n",
      "Epoch 5/10\n",
      "15663/15663 [==============================] - 4s 263us/step - loss: 0.7770 - val_loss: 0.8529\n",
      "Epoch 6/10\n",
      "15663/15663 [==============================] - 4s 262us/step - loss: 0.7589 - val_loss: 0.8449\n",
      "Epoch 7/10\n",
      "15663/15663 [==============================] - 4s 263us/step - loss: 0.7407 - val_loss: 0.8672\n",
      "Epoch 8/10\n",
      "15663/15663 [==============================] - 4s 279us/step - loss: 0.7173 - val_loss: 0.8686\n",
      "Epoch 9/10\n",
      "15663/15663 [==============================] - 4s 280us/step - loss: 0.7121 - val_loss: 0.8835\n",
      "Epoch 10/10\n",
      "15663/15663 [==============================] - 4s 280us/step - loss: 0.6874 - val_loss: 0.8758\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/10\n",
      "15663/15663 [==============================] - 9s 547us/step - loss: 1.1334 - val_loss: 0.8911\n",
      "Epoch 2/10\n",
      "15663/15663 [==============================] - 4s 268us/step - loss: 0.8690 - val_loss: 0.8421\n",
      "Epoch 3/10\n",
      "15663/15663 [==============================] - 4s 267us/step - loss: 0.8169 - val_loss: 0.8426\n",
      "Epoch 4/10\n",
      "15663/15663 [==============================] - 4s 261us/step - loss: 0.7927 - val_loss: 0.8506\n",
      "Epoch 5/10\n",
      "15663/15663 [==============================] - 4s 259us/step - loss: 0.7826 - val_loss: 0.8683\n",
      "Epoch 6/10\n",
      "15663/15663 [==============================] - 4s 270us/step - loss: 0.7566 - val_loss: 0.8489\n",
      "Epoch 7/10\n",
      "15663/15663 [==============================] - 4s 261us/step - loss: 0.7383 - val_loss: 0.8706\n",
      "Epoch 8/10\n",
      "15663/15663 [==============================] - 4s 257us/step - loss: 0.7198 - val_loss: 0.8656\n",
      "Epoch 9/10\n",
      "15663/15663 [==============================] - 4s 258us/step - loss: 0.7028 - val_loss: 0.8776\n",
      "Epoch 10/10\n",
      "15663/15663 [==============================] - 4s 274us/step - loss: 0.6859 - val_loss: 0.8683\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/10\n",
      "15663/15663 [==============================] - 8s 512us/step - loss: 1.1506 - val_loss: 0.9002\n",
      "Epoch 2/10\n",
      "15663/15663 [==============================] - 4s 246us/step - loss: 0.8692 - val_loss: 0.8543\n",
      "Epoch 3/10\n",
      "15663/15663 [==============================] - 4s 245us/step - loss: 0.8224 - val_loss: 0.8316\n",
      "Epoch 4/10\n",
      "15663/15663 [==============================] - 4s 248us/step - loss: 0.8001 - val_loss: 0.8658\n",
      "Epoch 5/10\n",
      "15663/15663 [==============================] - 4s 246us/step - loss: 0.7789 - val_loss: 0.8644\n",
      "Epoch 6/10\n",
      "15663/15663 [==============================] - 4s 251us/step - loss: 0.7613 - val_loss: 0.8452\n",
      "Epoch 7/10\n",
      "15663/15663 [==============================] - 4s 254us/step - loss: 0.7476 - val_loss: 0.8585\n",
      "Epoch 8/10\n",
      "15663/15663 [==============================] - 4s 250us/step - loss: 0.7223 - val_loss: 0.8609\n",
      "Epoch 9/10\n",
      "15663/15663 [==============================] - 4s 276us/step - loss: 0.7097 - val_loss: 0.8449\n",
      "Epoch 10/10\n",
      "15663/15663 [==============================] - 5s 299us/step - loss: 0.6897 - val_loss: 0.8375\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/10\n",
      "15663/15663 [==============================] - 9s 595us/step - loss: 1.1449 - val_loss: 0.9276\n",
      "Epoch 2/10\n",
      "15663/15663 [==============================] - 5s 300us/step - loss: 0.8755 - val_loss: 0.8588\n",
      "Epoch 3/10\n",
      "15663/15663 [==============================] - 5s 293us/step - loss: 0.8299 - val_loss: 0.8340\n",
      "Epoch 4/10\n",
      "15663/15663 [==============================] - 5s 295us/step - loss: 0.7948 - val_loss: 0.8301\n",
      "Epoch 5/10\n",
      "15663/15663 [==============================] - 5s 297us/step - loss: 0.7782 - val_loss: 0.8554\n",
      "Epoch 6/10\n",
      "15663/15663 [==============================] - 5s 300us/step - loss: 0.7605 - val_loss: 0.8332\n",
      "Epoch 7/10\n",
      "15663/15663 [==============================] - 5s 295us/step - loss: 0.7426 - val_loss: 0.8660\n",
      "Epoch 8/10\n",
      "15663/15663 [==============================] - 5s 299us/step - loss: 0.7287 - val_loss: 0.8455\n",
      "Epoch 9/10\n",
      "15663/15663 [==============================] - 5s 299us/step - loss: 0.7016 - val_loss: 0.8562\n",
      "Epoch 10/10\n",
      "15663/15663 [==============================] - 5s 295us/step - loss: 0.6890 - val_loss: 0.8561\n",
      "Train on 15664 samples, validate on 3915 samples\n",
      "Epoch 1/10\n",
      "15664/15664 [==============================] - 9s 598us/step - loss: 1.1467 - val_loss: 0.8940\n",
      "Epoch 2/10\n",
      "15664/15664 [==============================] - 4s 272us/step - loss: 0.8699 - val_loss: 0.8507\n",
      "Epoch 3/10\n",
      "15664/15664 [==============================] - 4s 275us/step - loss: 0.8157 - val_loss: 0.8614\n",
      "Epoch 4/10\n",
      "15664/15664 [==============================] - 4s 257us/step - loss: 0.7926 - val_loss: 0.8705\n",
      "Epoch 5/10\n",
      "15664/15664 [==============================] - 4s 263us/step - loss: 0.7749 - val_loss: 0.8519\n",
      "Epoch 6/10\n",
      "15664/15664 [==============================] - 4s 273us/step - loss: 0.7487 - val_loss: 0.8863\n",
      "Epoch 7/10\n",
      "15664/15664 [==============================] - 4s 274us/step - loss: 0.7347 - val_loss: 0.8713\n",
      "Epoch 8/10\n",
      "15664/15664 [==============================] - 4s 258us/step - loss: 0.7140 - val_loss: 0.8779\n",
      "Epoch 9/10\n",
      "15664/15664 [==============================] - 4s 261us/step - loss: 0.7038 - val_loss: 0.8992\n",
      "Epoch 10/10\n",
      "15664/15664 [==============================] - 4s 259us/step - loss: 0.6832 - val_loss: 0.9281\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "def doAddNN(X_train,X_test,pred_train,pred_test):\n",
    "    X_train[\"nn_eap\"] = pred_train[:,0]\n",
    "    X_train[\"nn_hpl\"] = pred_train[:,1]\n",
    "    X_train[\"nn_mws\"] = pred_train[:,2]\n",
    "    X_test[\"nn_eap\"] = pred_test[:,0]\n",
    "    X_test[\"nn_hpl\"] = pred_test[:,1]\n",
    "    X_test[\"nn_mws\"] = pred_test[:,2]\n",
    "    return X_train,X_test\n",
    "\n",
    "def initNN():\n",
    "    # create a simple 3 layer sequential neural net\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, input_dim=50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def doNN():\n",
    "    #glove_vecs_train,glove_vecs_test = doGlove(X_train['text'],X_test['text'])\n",
    "    # scale the data before any neural net:\n",
    "    embeddings_index = loadWordVecs()\n",
    "    scl = preprocessing.StandardScaler()\n",
    "    xtrain_glove_scl = scl.fit_transform(glove_vecs_train)\n",
    "    xtest_glove_scl = scl.transform(glove_vecs_test)\n",
    "\n",
    "    # we need to binarize the labels for the neural net\n",
    "    ytrain_enc = np_utils.to_categorical(Y_train)\n",
    "    #yvalid_enc = np_utils.to_categorical(yvalid)\n",
    "\n",
    "\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([xtrain_glove_scl.shape[0], 3])\n",
    "    for dev_index, val_index in kf.split(xtrain_glove_scl):\n",
    "        dev_X, val_X = xtrain_glove_scl[dev_index], xtrain_glove_scl[val_index]\n",
    "        dev_y, val_y = ytrain_enc[dev_index], ytrain_enc[val_index]\n",
    "        model = initNN()\n",
    "        model.fit(dev_X, y=dev_y, batch_size=100,epochs=10, verbose=1,validation_data=(val_X, val_y))\n",
    "        pred_val_y = model.predict(val_X)\n",
    "        pred_test_y = model.predict(xtest_glove_scl)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "\n",
    "    \n",
    "\n",
    "    # using keras tokenizer here\n",
    "#     token = text.Tokenizer(num_words=None)\n",
    "#     max_len = 70\n",
    "\n",
    "#     token.fit_on_texts(list(X_train['text']) + list(X_test['text']))\n",
    "#     xtrain_seq = token.texts_to_sequences(X_train['text'])\n",
    "#     xtest_seq = token.texts_to_sequences(X_test['text'])\n",
    "\n",
    "#     # zero pad the sequences\n",
    "#     xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "#     xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
    "\n",
    "#     word_index = token.word_index\n",
    "\n",
    "#     # create an embedding matrix for the words we have in the dataset\n",
    "#     embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "#     for word, i in tqdm(word_index.items()):\n",
    "#         embedding_vector = embeddings_index.get(word)\n",
    "#         if embedding_vector is not None:\n",
    "#             embedding_matrix[i] = embedding_vector\n",
    "\n",
    "#     # A simple LSTM with glove embeddings and two dense layers\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(len(word_index) + 1,\n",
    "#                          50,\n",
    "#                          weights=[embedding_matrix],\n",
    "#                          input_length=max_len,\n",
    "#                          trainable=False))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "#     model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(Dropout(0.8))\n",
    "\n",
    "#     model.add(Dense(1024, activation='relu'))\n",
    "#     model.add(Dropout(0.8))\n",
    "\n",
    "#     model.add(Dense(3))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "#     model.fit(xtrain_pad, y=ytrain_enc, batch_size=64, epochs=5, verbose=1)#, validation_data=(xvalid_pad, yvalid_enc))\n",
    "    return doAddNN(X_train,X_test,pred_train,pred_test)\n",
    "X_train,X_test = doNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 50)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.00288\ttest-mlogloss:1.00257\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.411797\ttest-mlogloss:0.417844\n",
      "[40]\ttrain-mlogloss:0.340403\ttest-mlogloss:0.353986\n",
      "[60]\ttrain-mlogloss:0.31472\ttest-mlogloss:0.336772\n",
      "[80]\ttrain-mlogloss:0.299552\ttest-mlogloss:0.329917\n",
      "[100]\ttrain-mlogloss:0.286775\ttest-mlogloss:0.32556\n",
      "[120]\ttrain-mlogloss:0.276183\ttest-mlogloss:0.323955\n",
      "[140]\ttrain-mlogloss:0.266659\ttest-mlogloss:0.321831\n",
      "[160]\ttrain-mlogloss:0.257829\ttest-mlogloss:0.321086\n",
      "[180]\ttrain-mlogloss:0.249448\ttest-mlogloss:0.320623\n",
      "[200]\ttrain-mlogloss:0.242359\ttest-mlogloss:0.320272\n",
      "[220]\ttrain-mlogloss:0.235114\ttest-mlogloss:0.319675\n",
      "[240]\ttrain-mlogloss:0.228824\ttest-mlogloss:0.319564\n",
      "[260]\ttrain-mlogloss:0.222932\ttest-mlogloss:0.319111\n",
      "[280]\ttrain-mlogloss:0.216638\ttest-mlogloss:0.318577\n",
      "[300]\ttrain-mlogloss:0.210651\ttest-mlogloss:0.317977\n",
      "[320]\ttrain-mlogloss:0.205292\ttest-mlogloss:0.318092\n",
      "[340]\ttrain-mlogloss:0.199789\ttest-mlogloss:0.318658\n",
      "Stopping. Best iteration:\n",
      "[299]\ttrain-mlogloss:0.210988\ttest-mlogloss:0.317717\n",
      "\n",
      "[0]\ttrain-mlogloss:1.00285\ttest-mlogloss:1.00363\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.410902\ttest-mlogloss:0.421456\n",
      "[40]\ttrain-mlogloss:0.337974\ttest-mlogloss:0.35712\n",
      "[60]\ttrain-mlogloss:0.312003\ttest-mlogloss:0.34104\n",
      "[80]\ttrain-mlogloss:0.295227\ttest-mlogloss:0.333974\n",
      "[100]\ttrain-mlogloss:0.282544\ttest-mlogloss:0.330146\n",
      "[120]\ttrain-mlogloss:0.271478\ttest-mlogloss:0.328317\n",
      "[140]\ttrain-mlogloss:0.261365\ttest-mlogloss:0.326645\n",
      "[160]\ttrain-mlogloss:0.252586\ttest-mlogloss:0.325882\n",
      "[180]\ttrain-mlogloss:0.244299\ttest-mlogloss:0.325707\n",
      "[200]\ttrain-mlogloss:0.237118\ttest-mlogloss:0.326014\n",
      "[220]\ttrain-mlogloss:0.229952\ttest-mlogloss:0.325896\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-mlogloss:0.247164\ttest-mlogloss:0.325249\n",
      "\n",
      "[0]\ttrain-mlogloss:1.00263\ttest-mlogloss:1.00397\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.409373\ttest-mlogloss:0.425997\n",
      "[40]\ttrain-mlogloss:0.337348\ttest-mlogloss:0.361726\n",
      "[60]\ttrain-mlogloss:0.314301\ttest-mlogloss:0.34654\n",
      "[80]\ttrain-mlogloss:0.298263\ttest-mlogloss:0.338978\n",
      "[100]\ttrain-mlogloss:0.28654\ttest-mlogloss:0.334936\n",
      "[120]\ttrain-mlogloss:0.275967\ttest-mlogloss:0.331846\n",
      "[140]\ttrain-mlogloss:0.266019\ttest-mlogloss:0.329434\n",
      "[160]\ttrain-mlogloss:0.25705\ttest-mlogloss:0.328615\n",
      "[180]\ttrain-mlogloss:0.249373\ttest-mlogloss:0.327617\n",
      "[200]\ttrain-mlogloss:0.241958\ttest-mlogloss:0.326822\n",
      "[220]\ttrain-mlogloss:0.235523\ttest-mlogloss:0.32628\n",
      "[240]\ttrain-mlogloss:0.228611\ttest-mlogloss:0.325905\n",
      "[260]\ttrain-mlogloss:0.222484\ttest-mlogloss:0.326011\n",
      "[280]\ttrain-mlogloss:0.216316\ttest-mlogloss:0.325739\n",
      "[300]\ttrain-mlogloss:0.210288\ttest-mlogloss:0.326514\n",
      "[320]\ttrain-mlogloss:0.205084\ttest-mlogloss:0.326333\n",
      "Stopping. Best iteration:\n",
      "[272]\ttrain-mlogloss:0.218478\ttest-mlogloss:0.325677\n",
      "\n",
      "[0]\ttrain-mlogloss:1.00279\ttest-mlogloss:1.00259\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.413296\ttest-mlogloss:0.415817\n",
      "[40]\ttrain-mlogloss:0.342522\ttest-mlogloss:0.350633\n",
      "[60]\ttrain-mlogloss:0.318869\ttest-mlogloss:0.334136\n",
      "[80]\ttrain-mlogloss:0.304237\ttest-mlogloss:0.326096\n",
      "[100]\ttrain-mlogloss:0.293662\ttest-mlogloss:0.320849\n",
      "[120]\ttrain-mlogloss:0.284045\ttest-mlogloss:0.317626\n",
      "[140]\ttrain-mlogloss:0.275298\ttest-mlogloss:0.31497\n",
      "[160]\ttrain-mlogloss:0.266826\ttest-mlogloss:0.312988\n",
      "[180]\ttrain-mlogloss:0.257628\ttest-mlogloss:0.310934\n",
      "[200]\ttrain-mlogloss:0.250488\ttest-mlogloss:0.310241\n",
      "[220]\ttrain-mlogloss:0.24357\ttest-mlogloss:0.309564\n",
      "[240]\ttrain-mlogloss:0.237199\ttest-mlogloss:0.308769\n",
      "[260]\ttrain-mlogloss:0.23028\ttest-mlogloss:0.308215\n",
      "[280]\ttrain-mlogloss:0.223982\ttest-mlogloss:0.307489\n",
      "[300]\ttrain-mlogloss:0.218473\ttest-mlogloss:0.307815\n",
      "[320]\ttrain-mlogloss:0.212573\ttest-mlogloss:0.307733\n",
      "Stopping. Best iteration:\n",
      "[282]\ttrain-mlogloss:0.223408\ttest-mlogloss:0.307427\n",
      "\n",
      "[0]\ttrain-mlogloss:0.999679\ttest-mlogloss:1.00099\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.412276\ttest-mlogloss:0.422785\n",
      "[40]\ttrain-mlogloss:0.339552\ttest-mlogloss:0.35713\n",
      "[60]\ttrain-mlogloss:0.317425\ttest-mlogloss:0.341435\n",
      "[80]\ttrain-mlogloss:0.302384\ttest-mlogloss:0.332692\n",
      "[100]\ttrain-mlogloss:0.29032\ttest-mlogloss:0.327702\n",
      "[120]\ttrain-mlogloss:0.279536\ttest-mlogloss:0.324059\n",
      "[140]\ttrain-mlogloss:0.270021\ttest-mlogloss:0.321468\n",
      "[160]\ttrain-mlogloss:0.261174\ttest-mlogloss:0.318705\n",
      "[180]\ttrain-mlogloss:0.253402\ttest-mlogloss:0.317206\n",
      "[200]\ttrain-mlogloss:0.24636\ttest-mlogloss:0.316174\n",
      "[220]\ttrain-mlogloss:0.239217\ttest-mlogloss:0.316037\n",
      "[240]\ttrain-mlogloss:0.232123\ttest-mlogloss:0.315752\n",
      "[260]\ttrain-mlogloss:0.225511\ttest-mlogloss:0.315218\n",
      "[280]\ttrain-mlogloss:0.218879\ttest-mlogloss:0.314408\n",
      "[300]\ttrain-mlogloss:0.21287\ttest-mlogloss:0.314809\n",
      "[320]\ttrain-mlogloss:0.206852\ttest-mlogloss:0.314348\n",
      "[340]\ttrain-mlogloss:0.200996\ttest-mlogloss:0.31357\n",
      "[360]\ttrain-mlogloss:0.195659\ttest-mlogloss:0.313564\n",
      "[380]\ttrain-mlogloss:0.190472\ttest-mlogloss:0.313908\n",
      "[400]\ttrain-mlogloss:0.185265\ttest-mlogloss:0.314281\n",
      "Stopping. Best iteration:\n",
      "[366]\ttrain-mlogloss:0.193983\ttest-mlogloss:0.31332\n",
      "\n",
      "('cv scores : ', [0.3177171701694026, 0.3252487718846494, 0.32567687416642571, 0.30742745552440848, 0.31332025744834135])\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "# XGBoost\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=0, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 3\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = child\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = colsample\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = 2000\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(test_X2)\n",
    "        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def do(X_train,X_test,Y_train):\n",
    "    drop_columns=[\"id\",\"text\",\"words\",\"word_vectors\",\"sentence_vectors\"]\n",
    "    x_train = X_train.drop(drop_columns+['author'],axis=1)\n",
    "    x_test = X_test.drop(drop_columns,axis=1)\n",
    "    y_train = Y_train\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([x_train.shape[0], 3])\n",
    "    for dev_index, val_index in kf.split(x_train):\n",
    "        dev_X, val_X = x_train.loc[dev_index], x_train.loc[val_index]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, x_test, seed_val=0, colsample=0.7)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"cv scores : \", cv_scores)\n",
    "    return pred_full_test/5\n",
    "result = do(X_train,X_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write Results\n",
    "\n",
    "def writeResult(result,test):\n",
    "    # count number of files\n",
    "    path, dirs, files = os.walk(\"../results\").next()\n",
    "    file_count = len(files)/2+1\n",
    "\n",
    "    # Write the test results\n",
    "    data=OrderedDict()\n",
    "    data[\"id\"]=test[\"id\"] \n",
    "    data[\"EAP\"]=result[0]#[\"EAP\"]\n",
    "    data[\"HPL\"]=result[1]#[\"HPL\"]\t\n",
    "    data[\"MWS\"]=result[2]#[\"MWS\"]\n",
    "    output = pd.DataFrame(data=data)\n",
    "    filename = \"../results/result\"+str(file_count)+\".csv\"\n",
    "    output.to_csv( filename, index=False )\n",
    "    filename = \"../results/result\"+str(file_count)+\"compr.csv\"\n",
    "    output.to_csv( filename, index=False )\n",
    "    check_call(['gzip', filename])\n",
    "\n",
    "writeResult(result.T,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>words</th>\n",
       "      <th>word_vectors</th>\n",
       "      <th>sentence_vectors</th>\n",
       "      <th>punc_1</th>\n",
       "      <th>punc_2</th>\n",
       "      <th>punc_3</th>\n",
       "      <th>punc_4</th>\n",
       "      <th>punc_5</th>\n",
       "      <th>punc_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, however, afforded, me, no, mea...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.102682611702, 0.843608723404, 0.6941906914...</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, once, occurred, to, me, that, the,...</td>\n",
       "      <td>[[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...</td>\n",
       "      <td>[-0.071579877193, 0.818990877193, 0.7487534035...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "      <td>[[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...</td>\n",
       "      <td>[-0.137265402439, 0.810834207317, 0.6727634268...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, lovely, is, spring, as, we, looked, from...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.0491552662722, 0.823676804734, 0.681447236...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[finding, nothing, else, not, even, gold, the,...</td>\n",
       "      <td>[[0.11891, 0.15255, -0.082073, -0.74144, 0.759...</td>\n",
       "      <td>[-0.0283006027397, 0.804272054795, 0.685995212...</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[a, youth, passed, in, solitude, my, best, yea...</td>\n",
       "      <td>[[0.11723, 1.0841, -0.053105, 1.5335, -0.14481...</td>\n",
       "      <td>[-0.0410986325459, 0.79631328084, 0.6697033727...</td>\n",
       "      <td>1.204819</td>\n",
       "      <td>6.024096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.228916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, astronomer, perhaps, at, this, point, to...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0840731495327, 0.857992523364, 0.664399906...</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>19.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, surcingle, hung, in, ribands, from, my, ...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.141073485714, 0.853343142857, 0.6402297428...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, knew, that, you, could, not, say, to, your...</td>\n",
       "      <td>[[-0.01397, 0.9522, 1.3895, 0.31898, 0.7499, 0...</td>\n",
       "      <td>[-0.0970629771574, 0.842538477157, 0.648277215...</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[i, confess, that, neither, the, structure, of...</td>\n",
       "      <td>[[-0.48882, 0.48228, 0.45726, 0.89723, 0.84066...</td>\n",
       "      <td>[-0.102452322314, 0.832763305785, 0.6967663719...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id16737</td>\n",
       "      <td>He shall find that I can feel my injuries; he ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[he, shall, find, that, i, can, feel, my, inju...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0156725421687, 0.79613, 0.652850626506, 0....</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>13.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id16607</td>\n",
       "      <td>Here we barricaded ourselves, and, for the pre...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[here, we, barricaded, ourselves, and, for, th...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[0.00396471698113, 0.765338113208, 0.746375283...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id19764</td>\n",
       "      <td>Herbert West needed fresh bodies because his l...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[herbert, west, needed, fresh, bodies, because...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0037754084507, 0.752586197183, 0.702424718...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id18886</td>\n",
       "      <td>The farm like grounds extended back very deepl...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[the, farm, like, grounds, extended, back, ver...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.00635960869565, 0.824465507246, 0.75860807...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id17189</td>\n",
       "      <td>But a glance will show the fallacy of this idea.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[but, a, glance, will, show, the, fallacy, of,...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.122360842105, 0.785797894737, 0.5819706842...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id12799</td>\n",
       "      <td>He had escaped me, and I must commence a destr...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[he, had, escaped, me, and, i, must, commence,...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0673836933962, 0.821568632075, 0.644750089...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.638298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id08441</td>\n",
       "      <td>To these speeches they gave, of course, their ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[to, these, speeches, they, gave, of, course, ...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.0516147527273, 0.812938290909, 0.606726054...</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>13.114754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.393443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id13117</td>\n",
       "      <td>Her native sprightliness needed no undue excit...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[her, native, sprightliness, needed, no, undue...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0245387931034, 0.802424344828, 0.730808220...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id14862</td>\n",
       "      <td>I even went so far as to speak of a slightly h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, even, went, so, far, as, to, speak, of, a,...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.082401321267, 0.797467013575, 0.6230455022...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id20836</td>\n",
       "      <td>His facial aspect, too, was remarkable for its...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[his, facial, aspect, too, was, remarkable, fo...</td>\n",
       "      <td>[[0.11891, 0.15255, -0.082073, -0.74144, 0.759...</td>\n",
       "      <td>[-0.0821343710938, 0.804547265625, 0.650076906...</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id11411</td>\n",
       "      <td>Now the net work was not permanently fastened ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[now, the, net, work, was, not, permanently, f...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.100865233333, 0.882924444444, 0.6921496, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id08075</td>\n",
       "      <td>It was not that the sounds were hideous, for t...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, was, not, that, the, sounds, were, hideou...</td>\n",
       "      <td>[[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...</td>\n",
       "      <td>[-0.0885751835749, 0.807114492754, 0.633884183...</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id18925</td>\n",
       "      <td>On every hand was a wilderness of balconies, o...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[on, every, hand, was, a, wilderness, of, balc...</td>\n",
       "      <td>[[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...</td>\n",
       "      <td>[-0.0622095051546, 0.794222783505, 0.545728463...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id19925</td>\n",
       "      <td>With how deep a spirit of wonder and perplexit...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[with, how, deep, a, spirit, of, wonder, and, ...</td>\n",
       "      <td>[[0.11891, 0.15255, -0.082073, -0.74144, 0.759...</td>\n",
       "      <td>[-0.0922515013333, 0.83638344, 0.660759725333,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.073171</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id01704</td>\n",
       "      <td>These bizarre attempts at explanation were fol...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[these, bizarre, attempts, at, explanation, we...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0471330447761, 0.814030447761, 0.690070910...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id10125</td>\n",
       "      <td>For many prodigies and signs had taken place, ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[for, many, prodigies, and, signs, had, taken,...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.0334929272727, 0.785343181818, 0.597201818...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id02448</td>\n",
       "      <td>All that as yet can fairly be said to be known...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[all, that, as, yet, can, fairly, be, said, to...</td>\n",
       "      <td>[[-0.2128, 0.97449, 1.0611, 1.0138, 0.1871, 0....</td>\n",
       "      <td>[-0.0698884073276, 0.802449482759, 0.644470446...</td>\n",
       "      <td>1.075269</td>\n",
       "      <td>9.677419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id23451</td>\n",
       "      <td>I seemed to be upon the verge of comprehension...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, seemed, to, be, upon, the, verge, of, comp...</td>\n",
       "      <td>[[-0.15234, 0.98085, 1.0065, 0.97812, 0.6628, ...</td>\n",
       "      <td>[-0.0626657651007, 0.858165234899, 0.770610483...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id27907</td>\n",
       "      <td>Our compasses, depth gauges, and other delicat...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[our, compasses, depth, gauges, and, other, de...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.108927077922, 0.845532164502, 0.7056157229...</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id08121</td>\n",
       "      <td>This the young warriors took back with them to...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[this, the, young, warriors, took, back, with,...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.111811843478, 0.840046869565, 0.5856778434...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19549</th>\n",
       "      <td>id20955</td>\n",
       "      <td>But it was not so; I was the same in strength,...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[but, it, was, not, so, i, was, the, same, in,...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.0905873152174, 0.836797717391, 0.619413641...</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>id01270</td>\n",
       "      <td>He then took the book himself, and read me a c...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[he, then, took, the, book, himself, and, read...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0226373191489, 0.802805319149, 0.657292489...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19551</th>\n",
       "      <td>id22290</td>\n",
       "      <td>\"Adolphe Le Bon, clerk to Mignaud et Fils, dep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[adolphe, le, bon, clerk, to, mignaud, et, fil...</td>\n",
       "      <td>[[0.25769, 0.45629, -0.76974, -0.37679, 0.5927...</td>\n",
       "      <td>[-0.0541682446043, 0.799541654676, 0.623836374...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19552</th>\n",
       "      <td>id20272</td>\n",
       "      <td>But of the character of his remarks at the per...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[but, of, the, character, of, his, remarks, at...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.0473347530864, 0.794191111111, 0.693726172...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19553</th>\n",
       "      <td>id18082</td>\n",
       "      <td>He notes every variation of face as the play p...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[he, notes, every, variation, of, face, as, th...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.103397680272, 0.825419115646, 0.6677028639...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>id07976</td>\n",
       "      <td>They admitted they had been drunk, but both vo...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[they, admitted, they, had, been, drunk, but, ...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0167904, 0.773475428571, 0.651574295238, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>id26741</td>\n",
       "      <td>The rays of the newly risen sun poured in upon...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, rays, of, the, newly, risen, sun, poured...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.115805269231, 0.882291442308, 0.7178044423...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>id26698</td>\n",
       "      <td>To the north on the craggy precipice a few pac...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[to, the, north, on, the, craggy, precipice, a...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.113700204918, 0.813791434426, 0.7047835163...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19557</th>\n",
       "      <td>id22265</td>\n",
       "      <td>The frauds of the banks of course I couldn't h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, frauds, of, the, banks, of, course, i, c...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.131138538462, 0.843428974359, 0.7332710256...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>id14778</td>\n",
       "      <td>He was attired, as I had expected, in a costum...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[he, was, attired, as, i, had, expected, in, a...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0749576369863, 0.784998972603, 0.605541815...</td>\n",
       "      <td>3.030303</td>\n",
       "      <td>12.121212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>id18823</td>\n",
       "      <td>When a fumbling came in the nearer casements h...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[when, a, fumbling, came, in, the, nearer, cas...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0769081322314, 0.823524628099, 0.724719636...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>id00893</td>\n",
       "      <td>But then there is the tone laconic, or curt, w...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[but, then, there, is, the, tone, laconic, or,...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.105288046154, 0.764170769231, 0.6915738923...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>id08678</td>\n",
       "      <td>Average people in society and business New Eng...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[average, people, in, society, and, business, ...</td>\n",
       "      <td>[[0.18445, 1.2654, 0.039013, 0.81299, -0.38684...</td>\n",
       "      <td>[-0.05395918107, 0.827846748971, 0.66893298353...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>15.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>id10857</td>\n",
       "      <td>The modes and sources of this kind of error ar...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, modes, and, sources, of, this, kind, of,...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.050257, 0.828303908046, 0.679545195402, 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>id10563</td>\n",
       "      <td>Yet from whom has not that rude hand rent away...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[yet, from, whom, has, not, that, rude, hand, ...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.116747927273, 0.876784, 0.661475218182, 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>id11752</td>\n",
       "      <td>Almighty God no, no They heard they suspected ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[almighty, god, no, no, they, heard, they, sus...</td>\n",
       "      <td>[[-0.2128, 0.97449, 1.0611, 1.0138, 0.1871, 0....</td>\n",
       "      <td>[-0.08603926, 0.8538628, 0.7014058, 0.7924282,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>id26214</td>\n",
       "      <td>I hope you have not been so foolish as to take...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, hope, you, have, not, been, so, foolish, a...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0669247311828, 0.814529247312, 0.608819763...</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>id00832</td>\n",
       "      <td>These reflections made our legislators pause, ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[these, reflections, made, our, legislators, p...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0449186547619, 0.801636785714, 0.704595035...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19567</th>\n",
       "      <td>id04187</td>\n",
       "      <td>Because there were some considerations of deep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[because, there, were, some, considerations, o...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[0.0226147222222, 0.804656111111, 0.7272656666...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>id22378</td>\n",
       "      <td>Before going in we walked up the street, turne...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[before, going, in, we, walked, up, the, stree...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.071154652968, 0.818071826484, 0.6915628949...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>id26790</td>\n",
       "      <td>Once my fancy was soothed with dreams of virtu...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[once, my, fancy, was, soothed, with, dreams, ...</td>\n",
       "      <td>[[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...</td>\n",
       "      <td>[-0.111691377049, 0.898772786885, 0.6111770819...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>id14263</td>\n",
       "      <td>Nay, you may have met with another whom you ma...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[nay, you, may, have, met, with, another, whom...</td>\n",
       "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
       "      <td>[-0.0784851868132, 0.847366098901, 0.578836120...</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>13.513514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.405405</td>\n",
       "      <td>18.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>id14420</td>\n",
       "      <td>My watch was still going, and told me that the...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[my, watch, was, still, going, and, told, me, ...</td>\n",
       "      <td>[[0.11723, 1.0841, -0.053105, 1.5335, -0.14481...</td>\n",
       "      <td>[-0.157967769231, 0.867877115385, 0.6177265192...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>id03325</td>\n",
       "      <td>But these and other difficulties attending res...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[but, these, and, other, difficulties, attendi...</td>\n",
       "      <td>[[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...</td>\n",
       "      <td>[-0.0560095509259, 0.825533055556, 0.682447245...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.843137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>id07567</td>\n",
       "      <td>Stress of weather drove us up the Adriatic Gul...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[stress, of, weather, drove, us, up, the, adri...</td>\n",
       "      <td>[[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...</td>\n",
       "      <td>[-0.0919334336283, 0.826288761062, 0.693634946...</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, could, have, fancied, while, i, looked, at...</td>\n",
       "      <td>[[-0.48882, 0.48228, 0.45726, 0.89723, 0.84066...</td>\n",
       "      <td>[-0.0700693333333, 0.738944022989, 0.630722597...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, lids, clenched, themselves, together, as...</td>\n",
       "      <td>[[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...</td>\n",
       "      <td>[-0.0149431333333, 0.799338, 0.751576311111, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[mais, il, faut, agir, that, is, to, say, a, f...</td>\n",
       "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
       "      <td>[-0.106395388889, 0.731987777778, 0.5290718518...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[for, an, item, of, news, like, this, it, stri...</td>\n",
       "      <td>[[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...</td>\n",
       "      <td>[-0.038773440678, 0.789792372881, 0.6248360169...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[he, laid, a, gnarled, claw, on, my, shoulder,...</td>\n",
       "      <td>[[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...</td>\n",
       "      <td>[-0.0813159195402, 0.82118908046, 0.6514459770...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "5      id22965  A youth passed in solitude, my best years spen...    MWS   \n",
       "6      id09674  The astronomer, perhaps, at this point, took r...    EAP   \n",
       "7      id13515        The surcingle hung in ribands from my body.    EAP   \n",
       "8      id19322  I knew that you could not say to yourself 'ste...    EAP   \n",
       "9      id00912  I confess that neither the structure of langua...    MWS   \n",
       "10     id16737  He shall find that I can feel my injuries; he ...    MWS   \n",
       "11     id16607  Here we barricaded ourselves, and, for the pre...    EAP   \n",
       "12     id19764  Herbert West needed fresh bodies because his l...    HPL   \n",
       "13     id18886  The farm like grounds extended back very deepl...    HPL   \n",
       "14     id17189   But a glance will show the fallacy of this idea.    EAP   \n",
       "15     id12799  He had escaped me, and I must commence a destr...    MWS   \n",
       "16     id08441  To these speeches they gave, of course, their ...    EAP   \n",
       "17     id13117  Her native sprightliness needed no undue excit...    MWS   \n",
       "18     id14862  I even went so far as to speak of a slightly h...    EAP   \n",
       "19     id20836  His facial aspect, too, was remarkable for its...    HPL   \n",
       "20     id11411  Now the net work was not permanently fastened ...    EAP   \n",
       "21     id08075  It was not that the sounds were hideous, for t...    HPL   \n",
       "22     id18925  On every hand was a wilderness of balconies, o...    EAP   \n",
       "23     id19925  With how deep a spirit of wonder and perplexit...    EAP   \n",
       "24     id01704  These bizarre attempts at explanation were fol...    EAP   \n",
       "25     id10125  For many prodigies and signs had taken place, ...    EAP   \n",
       "26     id02448  All that as yet can fairly be said to be known...    EAP   \n",
       "27     id23451  I seemed to be upon the verge of comprehension...    EAP   \n",
       "28     id27907  Our compasses, depth gauges, and other delicat...    HPL   \n",
       "29     id08121  This the young warriors took back with them to...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19549  id20955  But it was not so; I was the same in strength,...    MWS   \n",
       "19550  id01270  He then took the book himself, and read me a c...    EAP   \n",
       "19551  id22290  \"Adolphe Le Bon, clerk to Mignaud et Fils, dep...    EAP   \n",
       "19552  id20272  But of the character of his remarks at the per...    EAP   \n",
       "19553  id18082  He notes every variation of face as the play p...    EAP   \n",
       "19554  id07976  They admitted they had been drunk, but both vo...    HPL   \n",
       "19555  id26741  The rays of the newly risen sun poured in upon...    EAP   \n",
       "19556  id26698  To the north on the craggy precipice a few pac...    EAP   \n",
       "19557  id22265  The frauds of the banks of course I couldn't h...    EAP   \n",
       "19558  id14778  He was attired, as I had expected, in a costum...    EAP   \n",
       "19559  id18823  When a fumbling came in the nearer casements h...    HPL   \n",
       "19560  id00893  But then there is the tone laconic, or curt, w...    EAP   \n",
       "19561  id08678  Average people in society and business New Eng...    HPL   \n",
       "19562  id10857  The modes and sources of this kind of error ar...    EAP   \n",
       "19563  id10563  Yet from whom has not that rude hand rent away...    MWS   \n",
       "19564  id11752  Almighty God no, no They heard they suspected ...    EAP   \n",
       "19565  id26214  I hope you have not been so foolish as to take...    EAP   \n",
       "19566  id00832  These reflections made our legislators pause, ...    MWS   \n",
       "19567  id04187  Because there were some considerations of deep...    EAP   \n",
       "19568  id22378  Before going in we walked up the street, turne...    EAP   \n",
       "19569  id26790  Once my fancy was soothed with dreams of virtu...    MWS   \n",
       "19570  id14263  Nay, you may have met with another whom you ma...    MWS   \n",
       "19571  id14420  My watch was still going, and told me that the...    HPL   \n",
       "19572  id03325  But these and other difficulties attending res...    EAP   \n",
       "19573  id07567  Stress of weather drove us up the Adriatic Gul...    MWS   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                   words  \\\n",
       "0      [this, process, however, afforded, me, no, mea...   \n",
       "1      [it, never, once, occurred, to, me, that, the,...   \n",
       "2      [in, his, left, hand, was, a, gold, snuff, box...   \n",
       "3      [how, lovely, is, spring, as, we, looked, from...   \n",
       "4      [finding, nothing, else, not, even, gold, the,...   \n",
       "5      [a, youth, passed, in, solitude, my, best, yea...   \n",
       "6      [the, astronomer, perhaps, at, this, point, to...   \n",
       "7      [the, surcingle, hung, in, ribands, from, my, ...   \n",
       "8      [i, knew, that, you, could, not, say, to, your...   \n",
       "9      [i, confess, that, neither, the, structure, of...   \n",
       "10     [he, shall, find, that, i, can, feel, my, inju...   \n",
       "11     [here, we, barricaded, ourselves, and, for, th...   \n",
       "12     [herbert, west, needed, fresh, bodies, because...   \n",
       "13     [the, farm, like, grounds, extended, back, ver...   \n",
       "14     [but, a, glance, will, show, the, fallacy, of,...   \n",
       "15     [he, had, escaped, me, and, i, must, commence,...   \n",
       "16     [to, these, speeches, they, gave, of, course, ...   \n",
       "17     [her, native, sprightliness, needed, no, undue...   \n",
       "18     [i, even, went, so, far, as, to, speak, of, a,...   \n",
       "19     [his, facial, aspect, too, was, remarkable, fo...   \n",
       "20     [now, the, net, work, was, not, permanently, f...   \n",
       "21     [it, was, not, that, the, sounds, were, hideou...   \n",
       "22     [on, every, hand, was, a, wilderness, of, balc...   \n",
       "23     [with, how, deep, a, spirit, of, wonder, and, ...   \n",
       "24     [these, bizarre, attempts, at, explanation, we...   \n",
       "25     [for, many, prodigies, and, signs, had, taken,...   \n",
       "26     [all, that, as, yet, can, fairly, be, said, to...   \n",
       "27     [i, seemed, to, be, upon, the, verge, of, comp...   \n",
       "28     [our, compasses, depth, gauges, and, other, de...   \n",
       "29     [this, the, young, warriors, took, back, with,...   \n",
       "...                                                  ...   \n",
       "19549  [but, it, was, not, so, i, was, the, same, in,...   \n",
       "19550  [he, then, took, the, book, himself, and, read...   \n",
       "19551  [adolphe, le, bon, clerk, to, mignaud, et, fil...   \n",
       "19552  [but, of, the, character, of, his, remarks, at...   \n",
       "19553  [he, notes, every, variation, of, face, as, th...   \n",
       "19554  [they, admitted, they, had, been, drunk, but, ...   \n",
       "19555  [the, rays, of, the, newly, risen, sun, poured...   \n",
       "19556  [to, the, north, on, the, craggy, precipice, a...   \n",
       "19557  [the, frauds, of, the, banks, of, course, i, c...   \n",
       "19558  [he, was, attired, as, i, had, expected, in, a...   \n",
       "19559  [when, a, fumbling, came, in, the, nearer, cas...   \n",
       "19560  [but, then, there, is, the, tone, laconic, or,...   \n",
       "19561  [average, people, in, society, and, business, ...   \n",
       "19562  [the, modes, and, sources, of, this, kind, of,...   \n",
       "19563  [yet, from, whom, has, not, that, rude, hand, ...   \n",
       "19564  [almighty, god, no, no, they, heard, they, sus...   \n",
       "19565  [i, hope, you, have, not, been, so, foolish, a...   \n",
       "19566  [these, reflections, made, our, legislators, p...   \n",
       "19567  [because, there, were, some, considerations, o...   \n",
       "19568  [before, going, in, we, walked, up, the, stree...   \n",
       "19569  [once, my, fancy, was, soothed, with, dreams, ...   \n",
       "19570  [nay, you, may, have, met, with, another, whom...   \n",
       "19571  [my, watch, was, still, going, and, told, me, ...   \n",
       "19572  [but, these, and, other, difficulties, attendi...   \n",
       "19573  [stress, of, weather, drove, us, up, the, adri...   \n",
       "19574  [i, could, have, fancied, while, i, looked, at...   \n",
       "19575  [the, lids, clenched, themselves, together, as...   \n",
       "19576  [mais, il, faut, agir, that, is, to, say, a, f...   \n",
       "19577  [for, an, item, of, news, like, this, it, stri...   \n",
       "19578  [he, laid, a, gnarled, claw, on, my, shoulder,...   \n",
       "\n",
       "                                            word_vectors  \\\n",
       "0      [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "1      [[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...   \n",
       "2      [[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...   \n",
       "3      [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "4      [[0.11891, 0.15255, -0.082073, -0.74144, 0.759...   \n",
       "5      [[0.11723, 1.0841, -0.053105, 1.5335, -0.14481...   \n",
       "6      [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "7      [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "8      [[-0.01397, 0.9522, 1.3895, 0.31898, 0.7499, 0...   \n",
       "9      [[-0.48882, 0.48228, 0.45726, 0.89723, 0.84066...   \n",
       "10     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "11     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "12     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "13     [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "14     [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "15     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "16     [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "17     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "18     [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19     [[0.11891, 0.15255, -0.082073, -0.74144, 0.759...   \n",
       "20     [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "21     [[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...   \n",
       "22     [[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...   \n",
       "23     [[0.11891, 0.15255, -0.082073, -0.74144, 0.759...   \n",
       "24     [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "25     [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "26     [[-0.2128, 0.97449, 1.0611, 1.0138, 0.1871, 0....   \n",
       "27     [[-0.15234, 0.98085, 1.0065, 0.97812, 0.6628, ...   \n",
       "28     [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "29     [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "...                                                  ...   \n",
       "19549  [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "19550  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19551  [[0.25769, 0.45629, -0.76974, -0.37679, 0.5927...   \n",
       "19552  [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "19553  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19554  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19555  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19556  [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "19557  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19558  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19559  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19560  [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "19561  [[0.18445, 1.2654, 0.039013, 0.81299, -0.38684...   \n",
       "19562  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19563  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19564  [[-0.2128, 0.97449, 1.0611, 1.0138, 0.1871, 0....   \n",
       "19565  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19566  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19567  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19568  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "19569  [[-0.27004, 1.1144, 1.0493, 0.57924, 0.78968, ...   \n",
       "19570  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...   \n",
       "19571  [[0.11723, 1.0841, -0.053105, 1.5335, -0.14481...   \n",
       "19572  [[-0.25676, 0.8549, 1.1003, 0.95363, 0.36585, ...   \n",
       "19573  [[-0.37915, 0.61848, 0.9593, 0.90403, 0.36806,...   \n",
       "19574  [[-0.48882, 0.48228, 0.45726, 0.89723, 0.84066...   \n",
       "19575  [[-0.22701, 0.70329, 0.96125, 0.93479, 0.7205,...   \n",
       "19576  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...   \n",
       "19577  [[-0.043861, 1.3183, -0.03715, 0.85478, 0.1221...   \n",
       "19578  [[0.73833, 0.65451, 1.0873, 0.86066, -0.4834, ...   \n",
       "\n",
       "                                        sentence_vectors    punc_1     punc_2  \\\n",
       "0      [-0.102682611702, 0.843608723404, 0.6941906914...  4.878049  12.195122   \n",
       "1      [-0.071579877193, 0.818990877193, 0.7487534035...  0.000000   7.142857   \n",
       "2      [-0.137265402439, 0.810834207317, 0.6727634268...  0.000000  13.888889   \n",
       "3      [-0.0491552662722, 0.823676804734, 0.681447236...  0.000000  11.764706   \n",
       "4      [-0.0283006027397, 0.804272054795, 0.685995212...  3.703704  11.111111   \n",
       "5      [-0.0410986325459, 0.79631328084, 0.6697033727...  1.204819   6.024096   \n",
       "6      [-0.0840731495327, 0.857992523364, 0.664399906...  4.761905  19.047619   \n",
       "7      [-0.141073485714, 0.853343142857, 0.6402297428...  0.000000  12.500000   \n",
       "8      [-0.0970629771574, 0.842538477157, 0.648277215...  1.136364   9.090909   \n",
       "9      [-0.102452322314, 0.832763305785, 0.6967663719...  0.000000  13.043478   \n",
       "10     [-0.0156725421687, 0.79613, 0.652850626506, 0....  4.545455   4.545455   \n",
       "11     [0.00396471698113, 0.765338113208, 0.746375283...  0.000000  30.000000   \n",
       "12     [-0.0037754084507, 0.752586197183, 0.702424718...  0.000000   6.666667   \n",
       "13     [-0.00635960869565, 0.824465507246, 0.75860807...  0.000000  13.333333   \n",
       "14     [-0.122360842105, 0.785797894737, 0.5819706842...  0.000000  10.000000   \n",
       "15     [-0.0673836933962, 0.821568632075, 0.644750089...  0.000000  10.638298   \n",
       "16     [-0.0516147527273, 0.812938290909, 0.606726054...  3.278689  13.114754   \n",
       "17     [-0.0245387931034, 0.802424344828, 0.730808220...  0.000000  14.285714   \n",
       "18     [-0.082401321267, 0.797467013575, 0.6230455022...  0.000000  14.583333   \n",
       "19     [-0.0821343710938, 0.804547265625, 0.650076906...  2.083333  12.500000   \n",
       "20     [-0.100865233333, 0.882924444444, 0.6921496, 0...  0.000000   9.523810   \n",
       "21     [-0.0885751835749, 0.807114492754, 0.633884183...  2.272727   6.818182   \n",
       "22     [-0.0622095051546, 0.794222783505, 0.545728463...  0.000000  27.777778   \n",
       "23     [-0.0922515013333, 0.83638344, 0.660759725333,...  0.000000  17.073171   \n",
       "24     [-0.0471330447761, 0.814030447761, 0.690070910...  0.000000   9.090909   \n",
       "25     [-0.0334929272727, 0.785343181818, 0.597201818...  0.000000  16.000000   \n",
       "26     [-0.0698884073276, 0.802449482759, 0.644470446...  1.075269   9.677419   \n",
       "27     [-0.0626657651007, 0.858165234899, 0.770610483...  0.000000  16.129032   \n",
       "28     [-0.108927077922, 0.845532164502, 0.7056157229...  2.222222  13.333333   \n",
       "29     [-0.111811843478, 0.840046869565, 0.5856778434...  0.000000   6.666667   \n",
       "...                                                  ...       ...        ...   \n",
       "19549  [-0.0905873152174, 0.836797717391, 0.619413641...  4.545455  13.636364   \n",
       "19550  [-0.0226373191489, 0.802805319149, 0.657292489...  0.000000  16.666667   \n",
       "19551  [-0.0541682446043, 0.799541654676, 0.623836374...  0.000000  18.750000   \n",
       "19552  [-0.0473347530864, 0.794191111111, 0.693726172...  0.000000   5.263158   \n",
       "19553  [-0.103397680272, 0.825419115646, 0.6677028639...  0.000000  16.666667   \n",
       "19554  [-0.0167904, 0.773475428571, 0.651574295238, 0...  0.000000   9.523810   \n",
       "19555  [-0.115805269231, 0.882291442308, 0.7178044423...  0.000000  12.500000   \n",
       "19556  [-0.113700204918, 0.813791434426, 0.7047835163...  0.000000  12.500000   \n",
       "19557  [-0.131138538462, 0.843428974359, 0.7332710256...  0.000000  10.000000   \n",
       "19558  [-0.0749576369863, 0.784998972603, 0.605541815...  3.030303  12.121212   \n",
       "19559  [-0.0769081322314, 0.823524628099, 0.724719636...  0.000000   8.000000   \n",
       "19560  [-0.105288046154, 0.764170769231, 0.6915738923...  0.000000  18.750000   \n",
       "19561  [-0.05395918107, 0.827846748971, 0.66893298353...  0.000000   6.666667   \n",
       "19562  [-0.050257, 0.828303908046, 0.679545195402, 0....  0.000000   5.263158   \n",
       "19563  [-0.116747927273, 0.876784, 0.661475218182, 0....  0.000000   0.000000   \n",
       "19564  [-0.08603926, 0.8538628, 0.7014058, 0.7924282,...  0.000000  12.000000   \n",
       "19565  [-0.0669247311828, 0.814529247312, 0.608819763...  4.347826   8.695652   \n",
       "19566  [-0.0449186547619, 0.801636785714, 0.704595035...  0.000000  11.111111   \n",
       "19567  [0.0226147222222, 0.804656111111, 0.7272656666...  0.000000  11.111111   \n",
       "19568  [-0.071154652968, 0.818071826484, 0.6915628949...  0.000000  17.021277   \n",
       "19569  [-0.111691377049, 0.898772786885, 0.6111770819...  0.000000  21.428571   \n",
       "19570  [-0.0784851868132, 0.847366098901, 0.578836120...  2.702703  13.513514   \n",
       "19571  [-0.157967769231, 0.867877115385, 0.6177265192...  0.000000  14.285714   \n",
       "19572  [-0.0560095509259, 0.825533055556, 0.682447245...  0.000000   7.843137   \n",
       "19573  [-0.0919334336283, 0.826288761062, 0.693634946...  3.703704  11.111111   \n",
       "19574  [-0.0700693333333, 0.738944022989, 0.630722597...  0.000000  15.000000   \n",
       "19575  [-0.0149431333333, 0.799338, 0.751576311111, 0...  0.000000  10.000000   \n",
       "19576  [-0.106395388889, 0.731987777778, 0.5290718518...  0.000000  15.384615   \n",
       "19577  [-0.038773440678, 0.789792372881, 0.6248360169...  0.000000  13.333333   \n",
       "19578  [-0.0813159195402, 0.82118908046, 0.6514459770...  0.000000   9.090909   \n",
       "\n",
       "         punc_3     punc_4    punc_5     punc_6  \n",
       "0      0.000000   0.000000  0.000000  17.073171  \n",
       "1      0.000000   0.000000  0.000000   7.142857  \n",
       "2      0.000000   0.000000  0.000000  13.888889  \n",
       "3      0.000000   0.000000  0.000000  11.764706  \n",
       "4      0.000000   0.000000  0.000000  14.814815  \n",
       "5      0.000000   0.000000  0.000000   7.228916  \n",
       "6      0.000000   0.000000  0.000000  23.809524  \n",
       "7      0.000000   0.000000  0.000000  12.500000  \n",
       "8      0.000000   1.136364  0.000000  11.363636  \n",
       "9      0.000000   0.000000  0.000000  13.043478  \n",
       "10     0.000000   0.000000  4.545455  13.636364  \n",
       "11     0.000000   0.000000  0.000000  30.000000  \n",
       "12     0.000000   0.000000  0.000000   6.666667  \n",
       "13     0.000000   0.000000  0.000000  13.333333  \n",
       "14     0.000000   0.000000  0.000000  10.000000  \n",
       "15     0.000000   0.000000  0.000000  10.638298  \n",
       "16     0.000000   0.000000  0.000000  16.393443  \n",
       "17     0.000000   0.000000  0.000000  14.285714  \n",
       "18     0.000000   0.000000  0.000000  14.583333  \n",
       "19     0.000000   4.166667  0.000000  18.750000  \n",
       "20     0.000000   0.000000  0.000000   9.523810  \n",
       "21     0.000000   0.000000  0.000000   9.090909  \n",
       "22     0.000000   0.000000  0.000000  27.777778  \n",
       "23     1.219512   0.000000  0.000000  18.292683  \n",
       "24     0.000000   0.000000  0.000000   9.090909  \n",
       "25     0.000000   0.000000  0.000000  16.000000  \n",
       "26     0.000000   3.225806  0.000000  12.903226  \n",
       "27     0.000000   0.000000  0.000000  16.129032  \n",
       "28     0.000000   0.000000  0.000000  15.555556  \n",
       "29     0.000000   0.000000  0.000000   6.666667  \n",
       "...         ...        ...       ...        ...  \n",
       "19549  0.000000   0.000000  0.000000  18.181818  \n",
       "19550  0.000000   0.000000  0.000000  16.666667  \n",
       "19551  0.000000   3.125000  3.125000  25.000000  \n",
       "19552  0.000000   0.000000  0.000000   5.263158  \n",
       "19553  0.000000   0.000000  0.000000  16.666667  \n",
       "19554  0.000000   0.000000  0.000000   9.523810  \n",
       "19555  0.000000   0.000000  0.000000  12.500000  \n",
       "19556  0.000000   0.000000  0.000000  12.500000  \n",
       "19557  0.000000  10.000000  0.000000  20.000000  \n",
       "19558  0.000000   0.000000  0.000000  15.151515  \n",
       "19559  0.000000   0.000000  0.000000   8.000000  \n",
       "19560  0.000000   0.000000  0.000000  18.750000  \n",
       "19561  0.000000   4.444444  4.444444  15.555556  \n",
       "19562  0.000000   0.000000  0.000000   5.263158  \n",
       "19563  7.692308   0.000000  0.000000   7.692308  \n",
       "19564  0.000000   0.000000  0.000000  12.000000  \n",
       "19565  0.000000   0.000000  0.000000  13.043478  \n",
       "19566  0.000000   0.000000  0.000000  11.111111  \n",
       "19567  0.000000   0.000000  0.000000  11.111111  \n",
       "19568  0.000000   0.000000  0.000000  17.021277  \n",
       "19569  0.000000   0.000000  0.000000  21.428571  \n",
       "19570  0.000000   0.000000  5.405405  18.918919  \n",
       "19571  0.000000   0.000000  0.000000  14.285714  \n",
       "19572  0.000000   0.000000  0.000000   7.843137  \n",
       "19573  0.000000   0.000000  0.000000  14.814815  \n",
       "19574  0.000000   0.000000  0.000000  15.000000  \n",
       "19575  0.000000   0.000000  0.000000  10.000000  \n",
       "19576  0.000000   0.000000  0.000000  15.384615  \n",
       "19577  0.000000   0.000000  6.666667  13.333333  \n",
       "19578  0.000000   0.000000  0.000000   9.090909  \n",
       "\n",
       "[19579 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'text', u'author', u'words', u'word_vectors',\n",
       "       u'sentence_vectors', u'sent_vec_0', u'sent_vec_1', u'sent_vec_2',\n",
       "       u'sent_vec_3', u'sent_vec_4', u'sent_vec_5', u'sent_vec_6',\n",
       "       u'sent_vec_7', u'sent_vec_8', u'sent_vec_9', u'sent_vec_10',\n",
       "       u'sent_vec_11', u'sent_vec_12', u'sent_vec_13', u'sent_vec_14',\n",
       "       u'sent_vec_15', u'sent_vec_16', u'sent_vec_17', u'sent_vec_18',\n",
       "       u'sent_vec_19', u'sent_vec_20', u'sent_vec_21', u'sent_vec_22',\n",
       "       u'sent_vec_23', u'sent_vec_24', u'sent_vec_25', u'sent_vec_26',\n",
       "       u'sent_vec_27', u'sent_vec_28', u'sent_vec_29', u'sent_vec_30',\n",
       "       u'sent_vec_31', u'sent_vec_32', u'sent_vec_33', u'sent_vec_34',\n",
       "       u'sent_vec_35', u'sent_vec_36', u'sent_vec_37', u'sent_vec_38',\n",
       "       u'sent_vec_39', u'sent_vec_40', u'sent_vec_41', u'sent_vec_42',\n",
       "       u'sent_vec_43', u'sent_vec_44', u'sent_vec_45', u'sent_vec_46',\n",
       "       u'sent_vec_47', u'sent_vec_48', u'sent_vec_49', u'nn_eap', u'nn_hpl',\n",
       "       u'nn_mws', u'punc_1', u'punc_2', u'punc_3', u'punc_4', u'punc_5',\n",
       "       u'punc_6', u'stop_word', u'tfidf_words_nb_eap', u'tfidf_words_nb_hpl',\n",
       "       u'tfidf_words_nb_mws', u'tfidf_chars_nb_eap', u'tfidf_chars_nb_hpl',\n",
       "       u'tfidf_chars_nb_mws', u'count_words_nb_eap', u'count_words_nb_hpl',\n",
       "       u'count_words_nb_mws', u'count_chars_nb_eap', u'count_chars_nb_hpl',\n",
       "       u'count_chars_nb_mws'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
